import streamlit as st
import requests
import re
from datetime import datetime
import time
import csv
import io

def search_papers_api(query, limit=20):
    """Semantic Scholar APIã‚’ä½¿ç”¨ã—ã¦è«–æ–‡ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
    if not query:
        return []
    
    time.sleep(1)  # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã«1ç§’å¾…æ©Ÿ
    
    # Semantic Scholar API endpoint
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    
    # æ•™è‚²é–¢ä¿‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Š
    education_keywords = ["education", "learning", "teaching", "pedagogy", "educational"]
    enhanced_query = f"{query} {' OR '.join(education_keywords)}"
    
    params = {
        'query': enhanced_query,
        'limit': limit,
        'fields': 'paperId,title,authors,year,abstract,venue,citationCount,publicationDate,url'
    }
    
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            headers = {
                'User-Agent': 'Academic Paper Search Tool (educational use)',
                'Accept': 'application/json'
            }
            
            response = requests.get(base_url, params=params, headers=headers, timeout=15)
            
            if response.status_code == 429:
                if attempt < max_retries - 1:
                    wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    st.warning(f"APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    st.error("APIåˆ¶é™ã«ã‚ˆã‚Šæ¤œç´¢ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                    return []
            
            response.raise_for_status()
            data = response.json()
            
            papers = []
            for paper in data.get('data', []):
                # æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                title = paper.get('title') or ''
                abstract = paper.get('abstract') or ''
                title_abstract = (title + ' ' + abstract).lower()
                education_terms = ['education', 'learning', 'teaching', 'student', 'school', 'classroom', 'pedagogy', 'curriculum', 'instruction']
                
                if any(term in title_abstract for term in education_terms):
                    authors_list = paper.get('authors', [])
                    if authors_list:
                        authors_names = []
                        for author in authors_list:
                            if author and isinstance(author, dict):
                                name = author.get('name')
                                if name:
                                    authors_names.append(str(name))
                        authors_str = ', '.join(authors_names) if authors_names else 'è‘—è€…ä¸æ˜'
                    else:
                        authors_str = 'è‘—è€…ä¸æ˜'
                    
                    processed_paper = {
                        'title': str(title) if title else 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜',
                        'authors': authors_str,
                        'year': paper.get('year') if paper.get('year') is not None else 'å¹´åº¦ä¸æ˜',
                        'abstract': str(abstract) if abstract else 'æŠ„éŒ²ãªã—',
                        'venue': str(paper.get('venue')) if paper.get('venue') else 'æ²è¼‰èªŒä¸æ˜',
                        'citation_count': paper.get('citationCount', 0) or 0,
                        'url': str(paper.get('url')) if paper.get('url') else '',
                        'publication_date': str(paper.get('publicationDate')) if paper.get('publicationDate') else ''
                    }
                    papers.append(processed_paper)
            
            return papers
        
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                st.warning(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚{retry_delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
                continue
            else:
                st.error(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.info("ğŸ’¡ è§£æ±ºæ–¹æ³•: ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã¯æ¤œç´¢èªã‚’å¤‰æ›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
                return []
        except Exception as e:
            st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    return []

def highlight_text(text, search_terms):
    """æ¤œç´¢èªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹é–¢æ•°"""
    if not search_terms or not text or text == 'None':
        return str(text) if text else ''
    
    # æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦å®‰å…¨ã«å‡¦ç†
    text = str(text)
    search_terms = str(search_terms)
    
    # è¤‡æ•°ã®æ¤œç´¢èªã«å¯¾å¿œ
    terms = [term.strip() for term in search_terms.split() if term.strip()]
    highlighted_text = text
    
    for term in terms:
        if term:  # ç©ºæ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯
            # å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„æ¤œç´¢
            pattern = re.compile(re.escape(term), re.IGNORECASE)
            highlighted_text = pattern.sub(
                f'<mark style="background-color: #ffeb3b; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{term}</mark>',
                highlighted_text
            )
    
    return highlighted_text

def format_apa_citation(paper):
    """APA ver.7å½¢å¼ã§å¼•ç”¨æ–‡çŒ®ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    authors = paper.get('authors', 'è‘—è€…ä¸æ˜')
    year = paper.get('year', 'å¹´åº¦ä¸æ˜')
    title = paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
    venue = paper.get('venue', 'æ²è¼‰èªŒä¸æ˜')
    url = paper.get('url', '')
    
    # è‘—è€…åã®å‡¦ç†ï¼ˆAPAå½¢å¼: Last, F. M.ï¼‰
    if authors != 'è‘—è€…ä¸æ˜':
        # ç°¡ç•¥åŒ–ï¼šå®Ÿéš›ã®APAå½¢å¼ã§ã¯å§“åã®é †åºå¤‰æ›´ãŒå¿…è¦
        author_formatted = authors
    else:
        author_formatted = 'è‘—è€…ä¸æ˜'
    
    # å¹´åº¦ã®å‡¦ç†
    year_formatted = f"({year})" if year != 'å¹´åº¦ä¸æ˜' else "(å¹´åº¦ä¸æ˜)"
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã®å‡¦ç†ï¼ˆAPAå½¢å¼ã§ã¯æ–‡ã®æœ€åˆã®å˜èªã®ã¿å¤§æ–‡å­—ï¼‰
    title_formatted = title
    
    # æ²è¼‰èªŒã®å‡¦ç†ï¼ˆã‚¤ã‚¿ãƒªãƒƒã‚¯ä½“ã‚’ç¤ºã™ãŸã‚*ã§å›²ã‚€ï¼‰
    venue_formatted = f"*{venue}*" if venue != 'æ²è¼‰èªŒä¸æ˜' else "*æ²è¼‰èªŒä¸æ˜*"
    
    # URLå‡¦ç†
    url_formatted = f" {url}" if url else ""
    
    # APAå½¢å¼ã®å¼•ç”¨æ–‡çŒ®ä½œæˆ
    citation = f"{author_formatted} {year_formatted}. {title_formatted}. {venue_formatted}.{url_formatted}"
    
    return citation

def format_bibtex_citation(paper, index):
    """BibTeXå½¢å¼ã§å¼•ç”¨æ–‡çŒ®ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    # å¿…è¦ãªæƒ…å ±ã‚’å–å¾—
    title = paper.get('title', 'Unknown Title')
    authors = paper.get('authors', 'Unknown Author')
    year = paper.get('year', 'Unknown')
    venue = paper.get('venue', 'Unknown Venue')
    url = paper.get('url', '')
    
    # BibTeXç”¨ã®ã‚­ãƒ¼ã‚’ç”Ÿæˆï¼ˆè‘—è€…ã®å§“+å¹´åº¦+ã‚¿ã‚¤ãƒˆãƒ«ã®æœ€åˆã®å˜èªï¼‰
    first_author = authors.split(',')[0].split()[-1] if authors != 'Unknown Author' else 'Unknown'
    first_word = title.split()[0] if title != 'Unknown Title' else 'Unknown'
    bibtex_key = f"{first_author}{year}{first_word}".replace(' ', '').replace(',', '')
    
    # è‘—è€…åã‚’BibTeXå½¢å¼ã«å¤‰æ›ï¼ˆLast, First and Last, Firstï¼‰
    if authors != 'Unknown Author':
        author_list = [author.strip() for author in authors.split(',')]
        bibtex_authors = ' and '.join(author_list)
    else:
        bibtex_authors = 'Unknown Author'
    
    # è«–æ–‡ã®ç¨®é¡ã‚’åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
    venue_lower = venue.lower() if venue != 'Unknown Venue' else ''
    if any(word in venue_lower for word in ['conference', 'proceedings', 'workshop', 'symposium']):
        entry_type = 'inproceedings'
        venue_field = 'booktitle'
    elif any(word in venue_lower for word in ['journal', 'transactions', 'letters']):
        entry_type = 'article'
        venue_field = 'journal'
    else:
        entry_type = 'misc'
        venue_field = 'howpublished'
    
    # BibTeXå½¢å¼ã®æ–‡çŒ®æƒ…å ±ã‚’ä½œæˆ
    bibtex_entry = f"""@{entry_type}{{{bibtex_key},
  title = {{{title}}},
  author = {{{bibtex_authors}}},
  {venue_field} = {{{venue}}},
  year = {{{year}}}"""
    
    # URLãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    if url:
        bibtex_entry += f",\n  url = {{{url}}}"
    
    # æŠ„éŒ²ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    abstract = paper.get('abstract', '')
    if abstract and abstract != 'æŠ„éŒ²ãªã—' and len(abstract) > 10:
        # æŠ„éŒ²ã‚’é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
        clean_abstract = abstract.replace('{', '\\{').replace('}', '\\}').replace('%', '\\%')
        bibtex_entry += f",\n  abstract = {{{clean_abstract}}}"
    
    bibtex_entry += "\n}"
    
    return bibtex_entry

def create_csv_data(papers, search_query):
    """æ¤œç´¢çµæœã‚’CSVå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
    csv_data = []
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
    headers = [
        'No.', 'title', 'author', 'year', 'journal', 'cites', 
        'abstract', 'URL', 'APA style', 'search words', 'search date'
    ]
    csv_data.append(headers)
    
    # ãƒ‡ãƒ¼ã‚¿è¡Œ
    search_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    for i, paper in enumerate(papers, 1):
        row = [
            i,
            paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜'),
            paper.get('authors', 'è‘—è€…ä¸æ˜'),
            paper.get('year', 'å¹´åº¦ä¸æ˜'),
            paper.get('venue', 'æ²è¼‰èªŒä¸æ˜'),
            paper.get('citation_count', 0),
            paper.get('abstract', 'æŠ„éŒ²ãªã—'),
            paper.get('url', ''),
            format_apa_citation(paper),
            search_query,
            search_datetime
        ]
        csv_data.append(row)
    
    return csv_data

def create_csv_download(papers, search_query):
    """CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    csv_data = create_csv_data(papers, search_query)
    
    # StringIOã‚’ä½¿ç”¨ã—ã¦CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerows(csv_data)
    
    return output.getvalue()

def create_bibtex_data(papers):
    """ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã‚’BibTeXå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
    bibtex_entries = []
    
    for i, paper in enumerate(papers, 1):
        bibtex_entry = format_bibtex_citation(paper, i)
        bibtex_entries.append(bibtex_entry)
    
    # BibTeXå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
    header = f"""% BibTeX bibliography file
% Generated by Academic Paper Search Tool
% Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
% Total entries: {len(papers)}

"""
    
    return header + '\n\n'.join(bibtex_entries)

def display_paper_with_save(paper, search_query, index):
    """è«–æ–‡æƒ…å ±ã‚’ä¿å­˜ãƒœã‚¿ãƒ³ä»˜ãã§è¡¨ç¤ºã™ã‚‹é–¢æ•°"""
    with st.container():
        title = str(paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜'))
        highlighted_title = highlight_text(title, search_query)
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ä¿å­˜ãƒœã‚¿ãƒ³ã‚’åŒã˜è¡Œã«é…ç½®
        col1, col2 = st.columns([5, 1])
        with col1:
            st.markdown(f"### {index}. {highlighted_title}", unsafe_allow_html=True)
        with col2:
            # å€‹åˆ¥ä¿å­˜ãƒœã‚¿ãƒ³
            save_key = f"save_{index}_{hash(title)}"
            if st.button("ğŸ’¾", key=save_key, help="ã“ã®è«–æ–‡ã‚’ä¿å­˜"):
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                existing_titles = [p.get('title') for p in st.session_state.saved_papers]
                if title not in existing_titles:
                    st.session_state.saved_papers.append(paper)
                    st.success("è«–æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                    st.rerun()
                else:
                    st.warning("ã“ã®è«–æ–‡ã¯æ—¢ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")
        
        # è‘—è€…æƒ…å ±ã¨å¹´åº¦
        col1, col2, col3 = st.columns([3, 1, 1])
        with col1:
            authors = str(paper.get('authors', 'è‘—è€…ä¸æ˜'))
            st.markdown(f"**è‘—è€…:** {authors}")
        with col2:
            year = paper.get('year', 'å¹´åº¦ä¸æ˜')
            st.markdown(f"**å¹´åº¦:** {year}")
        with col3:
            citation_count = paper.get('citation_count', 0)
            st.markdown(f"**å¼•ç”¨æ•°:** {citation_count}")
        
        # æ²è¼‰èªŒæƒ…å ±
        venue = paper.get('venue')
        if venue and venue != 'æ²è¼‰èªŒä¸æ˜':
            st.markdown(f"**æ²è¼‰èªŒ:** {str(venue)}")
        
        # APAå¼•ç”¨å½¢å¼ã‚’è¡¨ç¤º
        apa_citation = format_apa_citation(paper)
        bibtex_citation = format_bibtex_citation(paper, index)
        
        col1, col2 = st.columns(2)
        with col1:
            with st.expander("ğŸ“ APAå¼•ç”¨å½¢å¼"):
                st.code(apa_citation, language="text")
        with col2:
            with st.expander("ğŸ“š BibTeXå¼•ç”¨å½¢å¼"):
                st.code(bibtex_citation, language="bibtex")
        
        # æŠ„éŒ²ï¼ˆãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãï¼‰
        abstract = paper.get('abstract')
        if abstract and abstract != 'æŠ„éŒ²ãªã—' and abstract != 'None':
            abstract_str = str(abstract)
            # æŠ„éŒ²ã‚’é©åˆ‡ãªé•·ã•ã«åˆ¶é™
            if len(abstract_str) > 300:
                truncated_abstract = abstract_str[:300] + "..."
                highlighted_abstract = highlight_text(truncated_abstract, search_query)
            else:
                highlighted_abstract = highlight_text(abstract_str, search_query)
            st.markdown(f"**æŠ„éŒ²:** {highlighted_abstract}", unsafe_allow_html=True)
        
        # è«–æ–‡ãƒªãƒ³ã‚¯
        url = paper.get('url')
        if url and url != '':
            st.markdown(f"[ğŸ“„ è«–æ–‡ã‚’èª­ã‚€]({url})")
        
        st.markdown("---")

def main():
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title="EduStudy",
        page_icon="ğŸ“š",
        layout="wide"
    )
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
    }
    .search-box {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .paper-card {
        background: white;
        padding: 1.5rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'saved_papers' not in st.session_state:
        st.session_state.saved_papers = []
    if 'last_search_query' not in st.session_state:
        st.session_state.last_search_query = ""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“š EduStudy</h1>
        <p>ä¸–ç•Œä¸­ã®æ•™è‚²é–¢ä¿‚è«–æ–‡ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œç´¢ã§ãã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ” æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        # æ¤œç´¢çµæœæ•°ã®è¨­å®š
        result_limit = st.slider(
            "æ¤œç´¢çµæœæ•°",
            min_value=5,
            max_value=100,
            value=20,
            step=5
        )
        
        # å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        current_year = datetime.now().year
        year_range = st.slider(
            "ç™ºè¡Œå¹´åº¦ç¯„å›²",
            min_value=1950,
            max_value=current_year,
            value=(2025, current_year),
            step=1
        )
        
        st.markdown("---")
        
        st.header("ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸè«–æ–‡")
        
        if st.session_state.saved_papers:
            st.success(f"ä¿å­˜æ¸ˆã¿: {len(st.session_state.saved_papers)}ä»¶")
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            if st.button("ğŸ“¥ Download for CSV file", use_container_width=True):
                csv_content = create_csv_download(
                    st.session_state.saved_papers, 
                    st.session_state.last_search_query
                )
                
                filename = f"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                
                st.download_button(
                    label="ğŸ“„ Download for CSV file",
                    data=csv_content,
                    file_name=filename,
                    mime="text/csv",
                    use_container_width=True
                )
            
            # BibTeXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            if st.button("ğŸ“š Download for BibTeX file", use_container_width=True):
                bibtex_content = create_bibtex_data(st.session_state.saved_papers)
                
                filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.bib"
                
                st.download_button(
                    label="ğŸ“– Download for BibTeX file",
                    data=bibtex_content,
                    file_name=filename,
                    mime="text/plain",
                    use_container_width=True
                )
            
            # ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
            if st.button("ğŸ—‘ï¸ ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
                st.session_state.saved_papers = []
                st.success("ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                st.rerun()
            
            # ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã®ä¸€è¦§è¡¨ç¤º
            with st.expander("ğŸ“‹ ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ä¸€è¦§"):
                for i, paper in enumerate(st.session_state.saved_papers, 1):
                    st.write(f"{i}. {paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')}")
                    st.write(f"   è‘—è€…: {paper.get('authors', 'è‘—è€…ä¸æ˜')}")
                    st.write(f"   å¹´åº¦: {paper.get('year', 'å¹´åº¦ä¸æ˜')}")
                    st.write("---")
        else:
            st.info("ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        st.markdown("---")
        
        st.markdown("**ğŸ’¡ æ¤œç´¢ã®ãƒ’ãƒ³ãƒˆ:**")
        st.markdown("- æ—¥æœ¬èªã¾ãŸã¯è‹±èªã§æ¤œç´¢å¯èƒ½")
        st.markdown("- è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›")
        st.markdown("- æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã«ç‰¹åŒ–ã—ã¦æ¤œç´¢")
        st.markdown("- å¼•ç”¨æ•°ã®å¤šã„è«–æ–‡ãŒä¸Šä½ã«è¡¨ç¤º")
        
        st.markdown("---")
        st.markdown("**ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:**")
        st.markdown("- Semantic Scholar API")
        st.markdown("- 200M+ å­¦è¡“è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
        st.markdown("- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°")
    
    # ãƒ¡ã‚¤ãƒ³æ¤œç´¢ã‚¨ãƒªã‚¢
    st.markdown('<div class="search-box">', unsafe_allow_html=True)
    
    col1, col2 = st.columns([4, 1])
    
    with col1:
        search_query = st.text_input(
            "ğŸ” æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: ãƒ‡ã‚¸ã‚¿ãƒ«æ•™æ, collaborative learning, AI education",
            help="æ—¥æœ¬èªã¾ãŸã¯è‹±èªã§æ¤œç´¢ã§ãã¾ã™ã€‚è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        )
    
    with col2:
        search_button = st.button("ğŸš€ æ¤œç´¢é–‹å§‹", type="primary", use_container_width=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # æ¤œç´¢å®Ÿè¡Œ
    if search_query and (search_button or search_query):
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ä¿å­˜
        st.session_state.last_search_query = search_query
        
        with st.spinner("ğŸ” è«–æ–‡ã‚’æ¤œç´¢ä¸­..."):
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("Semantic Scholar APIã«æ¥ç¶šä¸­...")
            progress_bar.progress(25)
            
            # APIæ¤œç´¢å®Ÿè¡Œ
            results = search_papers_api(search_query, result_limit)
            progress_bar.progress(75)
            
            # å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if results:
                filtered_results = [
                    paper for paper in results 
                    if paper['year'] != 'å¹´åº¦ä¸æ˜' and 
                    isinstance(paper['year'], int) and 
                    year_range[0] <= paper['year'] <= year_range[1]
                ]
                results = filtered_results
            
            progress_bar.progress(100)
            status_text.text("æ¤œç´¢å®Œäº†!")
            time.sleep(0.5)
            progress_bar.empty()
            status_text.empty()
        
        # çµæœè¡¨ç¤º
        st.markdown(f"## ğŸ“Š æ¤œç´¢çµæœ: {len(results)}ä»¶")
        
        if results:
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ’¾ å…¨ã¦ã®çµæœã‚’ä¿å­˜", type="secondary"):
                    # é‡è¤‡ã‚’é¿ã‘ã¦ä¿å­˜
                    new_papers = []
                    existing_titles = [p.get('title') for p in st.session_state.saved_papers]
                    
                    for paper in results:
                        if paper.get('title') not in existing_titles:
                            new_papers.append(paper)
                    
                    st.session_state.saved_papers.extend(new_papers)
                    st.success(f"{len(new_papers)}ä»¶ã®æ–°ã—ã„è«–æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
                    st.rerun()
            
            with col2:
                if st.session_state.saved_papers:
                    download_format = st.selectbox(
                        "The Download Format",
                        ["CSV", "BibTeX"],
                        key="download_format_main"
                    )
                    
                    if download_format == "CSV":
                        csv_content = create_csv_download(
                            st.session_state.saved_papers, 
                            search_query
                        )
                        filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                        mime_type = "text/csv"
                        file_content = csv_content
                        button_label = "ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                    else:  # BibTeX
                        bibtex_content = create_bibtex_data(st.session_state.saved_papers)
                        filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.bib"
                        mime_type = "text/plain"
                        file_content = bibtex_content
                        button_label = "ğŸ“š BibTeXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                    
                    st.download_button(
                        label=button_label,
                        data=file_content,
                        file_name=filename,
                        mime=mime_type,
                        type="primary"
                    )
            
            # å„è«–æ–‡ã®è¡¨ç¤º
            for i, paper in enumerate(results, 1):
                display_paper_with_save(paper, search_query, i)
                
        else:
            st.warning("ğŸ” æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.markdown("""
            **ğŸ’¡ æ¤œç´¢ã®ã‚³ãƒ„:**
            - ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã¿ã¦ãã ã•ã„
            - è‹±èªã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚è©¦ã—ã¦ã¿ã¦ãã ã•ã„
            - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ•°ã‚’æ¸›ã‚‰ã—ã¦ã¿ã¦ãã ã•ã„
            - å¹´åº¦ç¯„å›²ã‚’åºƒã’ã¦ã¿ã¦ãã ã•ã„
            """)
    
    else:
        # åˆæœŸè¡¨ç¤ºï¼šã‚·ã‚¹ãƒ†ãƒ èª¬æ˜
        st.markdown("## ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ğŸ” æ¤œç´¢æ©Ÿèƒ½
            - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢**: Semantic Scholar APIã‚’ä½¿ç”¨
            - **å¤šè¨€èªå¯¾å¿œ**: æ—¥æœ¬èªãƒ»è‹±èªã§ã®æ¤œç´¢ãŒå¯èƒ½
            - **æ•™è‚²ç‰¹åŒ–**: æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã«ç‰¹åŒ–ã—ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            - **ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º**: æ¤œç´¢èªã‚’çµæœå†…ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            """)
            
        with col2:
            st.markdown("""
            ### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            - **200M+ è«–æ–‡**: ä¸–ç•Œæœ€å¤§ç´šã®å­¦è¡“è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°**: æœ€æ–°ã®ç ”ç©¶æˆæœã‚’å³åº§ã«æ¤œç´¢
            - **å¼•ç”¨æƒ…å ±**: è«–æ–‡ã®å½±éŸ¿åº¦ã‚’å¼•ç”¨æ•°ã§ç¢ºèª
            - **ç›´æ¥ãƒªãƒ³ã‚¯**: è«–æ–‡ã®åŸæ–‡ã¸ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
            """)
        
        st.markdown("---")
        
        st.markdown("""
        ### ğŸš€ ä½¿ã„æ–¹
        1. **æ¤œç´¢èªå…¥åŠ›**: ä¸Šã®æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã«é–¢å¿ƒã®ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›
        2. **ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¤œç´¢çµæœæ•°ã‚„å¹´åº¦ç¯„å›²ã‚’èª¿æ•´
        3. **æ¤œç´¢å®Ÿè¡Œ**: ã€Œæ¤œç´¢é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        4. **çµæœç¢ºèª**: ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã•ã‚ŒãŸæ¤œç´¢çµæœã‚’ç¢ºèª
        5. **è«–æ–‡é–²è¦§**: æ°—ã«ãªã‚‹è«–æ–‡ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦åŸæ–‡ã‚’èª­ã‚€
        """)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray; font-size: 0.8em; padding: 2rem;'>
        <p>ğŸ“š EduStudy: æ•™è‚²é–¢ä¿‚å­¦ä¼šèªŒè«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ </p>
        <p>Powered by Semantic Scholar API | ãƒ‡ãƒ¼ã‚¿ã¯å®šæœŸçš„ã«æ›´æ–°ã•ã‚Œã¾ã™</p>
        <p>ç ”ç©¶è€…ã®å­¦è¡“æ´»å‹•ã‚’æ”¯æ´ã—ã¾ã™</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
