import streamlit as st
import requests
import re
from datetime import datetime
import time
import csv
import io

try:
    from scholarly import scholarly
    GOOGLE_SCHOLAR_AVAILABLE = True
except ImportError:
    GOOGLE_SCHOLAR_AVAILABLE = False

def parse_search_query(query):
    """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è§£æã—ã¦ã€å¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸèªå¥ã‚’å®Œå…¨ä¸€è‡´ã¨ã—ã¦å‡¦ç†ã™ã‚‹é–¢æ•°"""
    if not query:
        return ""
    
    # å¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸèªå¥ã‚’æŠ½å‡º
    quoted_phrases = re.findall(r'"([^"]*)"', query)
    
    # å¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸèªå¥ã‚’ä¸€æ™‚çš„ã«ç½®æ›
    temp_query = query
    for i, phrase in enumerate(quoted_phrases):
        temp_query = temp_query.replace(f'"{phrase}"', f'__QUOTED_{i}__')
    
    # æ®‹ã‚Šã®å˜èªã‚’æŠ½å‡º
    remaining_words = temp_query.split()
    remaining_words = [word for word in remaining_words if not word.startswith('__QUOTED_')]
    
    # Semantic Scholarç”¨ã®ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
    query_parts = []
    
    # å¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸèªå¥ã¯å®Œå…¨ä¸€è‡´ã¨ã—ã¦è¿½åŠ 
    for phrase in quoted_phrases:
        if phrase.strip():
            query_parts.append(f'"{phrase.strip()}"')
    
    # æ®‹ã‚Šã®å˜èªã‚’è¿½åŠ 
    for word in remaining_words:
        if word.strip():
            query_parts.append(word.strip())
    
    return ' '.join(query_parts)

def search_papers_api(query, limit=20):
    """Semantic Scholar APIã‚’ä½¿ç”¨ã—ã¦è«–æ–‡ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
    if not query:
        return []
    
    time.sleep(1)  # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã«1ç§’å¾…æ©Ÿ
    
    # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è§£æ
    processed_query = parse_search_query(query)
    
    # Semantic Scholar API endpoint
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    
    # æ•™è‚²é–¢ä¿‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Š
    education_keywords = ["education", "learning", "teaching", "pedagogy", "educational"]
    enhanced_query = f"{processed_query} ({' OR '.join(education_keywords)})"
    
    params = {
        'query': enhanced_query,
        'limit': limit,
        'fields': 'paperId,title,authors,year,abstract,venue,citationCount,publicationDate,url'
    }
    
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            headers = {
                'User-Agent': 'EduStudy Academic Paper Search Tool (educational use)',
                'Accept': 'application/json'
            }
            
            response = requests.get(base_url, params=params, headers=headers, timeout=15)
            
            if response.status_code == 429:
                if attempt < max_retries - 1:
                    wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    st.warning(f"APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    st.error("APIåˆ¶é™ã«ã‚ˆã‚Šæ¤œç´¢ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                    return []
            
            response.raise_for_status()
            data = response.json()
            
            papers = []
            for paper in data.get('data', []):
                # æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                title = paper.get('title') or ''
                abstract = paper.get('abstract') or ''
                title_abstract = (title + ' ' + abstract).lower()
                education_terms = ['education', 'learning', 'teaching', 'student', 'school', 'classroom', 'pedagogy', 'curriculum', 'instruction']
                
                if any(term in title_abstract for term in education_terms):
                    authors_list = paper.get('authors', [])
                    if authors_list:
                        authors_names = []
                        for author in authors_list:
                            if author and isinstance(author, dict):
                                name = author.get('name')
                                if name:
                                    authors_names.append(str(name))
                        authors_str = ', '.join(authors_names) if authors_names else 'è‘—è€…ä¸æ˜'
                    else:
                        authors_str = 'è‘—è€…ä¸æ˜'
                    
                    processed_paper = {
                        'title': str(title) if title else 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜',
                        'authors': authors_str,
                        'year': paper.get('year') if paper.get('year') is not None else 'å¹´åº¦ä¸æ˜',
                        'abstract': str(abstract) if abstract else 'æŠ„éŒ²ãªã—',
                        'venue': str(paper.get('venue')) if paper.get('venue') else 'æ²è¼‰èªŒä¸æ˜',
                        'citation_count': paper.get('citationCount', 0) or 0,
                        'url': str(paper.get('url')) if paper.get('url') else '',
                        'publication_date': str(paper.get('publicationDate')) if paper.get('publicationDate') else '',
                        'source': 'Semantic Scholar'
                    }
                    papers.append(processed_paper)
            
            return papers
        
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                st.warning(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚{retry_delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
                continue
            else:
                st.error(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.info("ğŸ’¡ è§£æ±ºæ–¹æ³•: ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã¯æ¤œç´¢èªã‚’å¤‰æ›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
                return []
        except Exception as e:
            st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    return []

def search_google_scholar(query, limit=10):
    """Google Scholarã‚’ä½¿ç”¨ã—ã¦è«–æ–‡ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
    if not GOOGLE_SCHOLAR_AVAILABLE:
        return []
    
    if not query:
        return []
    
    papers = []
    try:
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚„User-Agentè¨­å®šã‚’è¿½åŠ 
        from scholarly import scholarly
        
        # æ¤œç´¢è¨­å®šã‚’èª¿æ•´
        try:
            # Google Scholaræ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼‰
            search_query = scholarly.search_pubs(query)
            
            count = 0
            timeout_count = 0
            max_timeout = 3  # æœ€å¤§3å›ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¾ã§è¨±å®¹
            
            for paper in search_query:
                if count >= limit:
                    break
                
                if timeout_count >= max_timeout:
                    st.warning("Google Scholaræ¤œç´¢ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒå¤šç™ºã—ã¦ã„ã¾ã™ã€‚Semantic Scholaræ¤œç´¢çµæœã®ã¿è¡¨ç¤ºã—ã¾ã™ã€‚")
                    break
                
                try:
                    # è«–æ–‡æƒ…å ±ã‚’å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ï¼‰
                    title = paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
                    authors = ', '.join([author['name'] for author in paper.get('author', [])]) if paper.get('author') else 'è‘—è€…ä¸æ˜'
                    year = paper.get('year', 'å¹´åº¦ä¸æ˜')
                    abstract = paper.get('abstract', 'æŠ„éŒ²ãªã—')
                    venue = paper.get('venue', 'æ²è¼‰èªŒä¸æ˜')
                    citation_count = paper.get('num_citations', 0)
                    url = paper.get('pub_url', '')
                    
                    # æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    title_abstract = (str(title) + ' ' + str(abstract)).lower()
                    education_terms = ['education', 'learning', 'teaching', 'student', 'school', 'classroom', 'pedagogy', 'curriculum', 'instruction']
                    
                    if any(term in title_abstract for term in education_terms):
                        processed_paper = {
                            'title': str(title) if title else 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜',
                            'authors': str(authors) if authors else 'è‘—è€…ä¸æ˜',
                            'year': int(year) if str(year).isdigit() else 'å¹´åº¦ä¸æ˜',
                            'abstract': str(abstract) if abstract else 'æŠ„éŒ²ãªã—',
                            'venue': str(venue) if venue else 'æ²è¼‰èªŒä¸æ˜',
                            'citation_count': int(citation_count) if citation_count else 0,
                            'url': str(url) if url else '',
                            'publication_date': '',
                            'source': 'Google Scholar'
                        }
                        papers.append(processed_paper)
                        count += 1
                    
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆã‚ˆã‚Šé•·ã„å¾…æ©Ÿæ™‚é–“ï¼‰
                    time.sleep(3)
                    
                except Exception as e:
                    timeout_count += 1
                    st.warning(f"Google Scholarè«–æ–‡å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆ{timeout_count}/{max_timeout}ï¼‰")
                    time.sleep(5)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚ˆã‚Šé•·ãå¾…æ©Ÿ
                    continue
                    
        except Exception as e:
            # Google Scholaræ¥ç¶šã‚¨ãƒ©ãƒ¼ã®è©³ç´°ãªãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            error_msg = str(e).lower()
            if "cannot fetch" in error_msg or "blocked" in error_msg:
                st.warning("âš ï¸ Google Scholarã‹ã‚‰ã®æ¤œç´¢ãŒä¸€æ™‚çš„ã«åˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚Semantic Scholaræ¤œç´¢çµæœã®ã¿è¡¨ç¤ºã—ã¾ã™ã€‚")
                st.info("ğŸ’¡ ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚ã¾ãŸã¯æ¤œç´¢èªã‚’å¤‰æ›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
            else:
                st.warning(f"Google Scholaræ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return []
                
    except ImportError:
        st.warning("Google Scholaræ¤œç´¢ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆscholarlyãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ï¼‰")
        return []
    except Exception as e:
        st.error(f"Google Scholaræ¤œç´¢ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []
    
    return papers

def search_combined(query, limit_per_source=10):
    """è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰è«–æ–‡ã‚’æ¤œç´¢ã—ã¦çµåˆã™ã‚‹é–¢æ•°"""
    all_papers = []
    
    # Semantic Scholaræ¤œç´¢
    st.info("ğŸ” Semantic Scholarã§æ¤œç´¢ä¸­...")
    semantic_papers = search_papers_api(query, limit_per_source)
    for paper in semantic_papers:
        paper['source'] = 'Semantic Scholar'
    all_papers.extend(semantic_papers)
    
    # Google Scholaræ¤œç´¢ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    if GOOGLE_SCHOLAR_AVAILABLE:
        st.info("ğŸ” Google Scholarã§æ¤œç´¢ä¸­...")
        try:
            google_papers = search_google_scholar(query, limit_per_source)
            all_papers.extend(google_papers)
        except Exception as e:
            st.warning(f"Google Scholaræ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    else:
        st.warning("Google Scholaræ¤œç´¢ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆscholarlyãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ï¼‰")
    
    # é‡è¤‡é™¤å»ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
    seen_titles = set()
    unique_papers = []
    for paper in all_papers:
        title_lower = paper.get('title', '').lower().strip()
        if title_lower and title_lower not in seen_titles:
            seen_titles.add(title_lower)
            unique_papers.append(paper)
    
    # å¼•ç”¨æ•°ã§ã‚½ãƒ¼ãƒˆ
    unique_papers.sort(key=lambda x: x.get('citation_count', 0), reverse=True)
    
    return unique_papers

def highlight_text(text, search_terms):
    """æ¤œç´¢èªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹é–¢æ•°ï¼ˆå¼•ç”¨ç¬¦å¯¾å¿œï¼‰"""
    if not search_terms or not text or text == 'None':
        return str(text) if text else ''
    
    # æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦å®‰å…¨ã«å‡¦ç†
    text = str(text)
    search_terms = str(search_terms)
    
    # å¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸèªå¥ã‚’æŠ½å‡º
    quoted_phrases = re.findall(r'"([^"]*)"', search_terms)
    
    # å¼•ç”¨ç¬¦ã§å›²ã¾ã‚Œã¦ã„ãªã„å˜èªã‚’æŠ½å‡º
    temp_terms = search_terms
    for phrase in quoted_phrases:
        temp_terms = temp_terms.replace(f'"{phrase}"', '')
    
    individual_words = [term.strip() for term in temp_terms.split() if term.strip()]
    
    highlighted_text = text
    
    # å¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸèªå¥ã‚’å®Œå…¨ä¸€è‡´ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    for phrase in quoted_phrases:
        if phrase.strip():
            pattern = re.compile(re.escape(phrase.strip()), re.IGNORECASE)
            highlighted_text = pattern.sub(
                f'<mark style="background-color: #ffeb3b; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{phrase.strip()}</mark>',
                highlighted_text
            )
    
    # å€‹åˆ¥ã®å˜èªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    for word in individual_words:
        if word:
            pattern = re.compile(re.escape(word), re.IGNORECASE)
            highlighted_text = pattern.sub(
                f'<mark style="background-color: #e1f5fe; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{word}</mark>',
                highlighted_text
            )
    
    return highlighted_text

def format_apa_citation(paper):
    """APA ver.7å½¢å¼ã§å¼•ç”¨æ–‡çŒ®ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    authors = paper.get('authors', 'è‘—è€…ä¸æ˜')
    year = paper.get('year', 'å¹´åº¦ä¸æ˜')
    title = paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
    venue = paper.get('venue', 'æ²è¼‰èªŒä¸æ˜')
    url = paper.get('url', '')
    
    # è‘—è€…åã®å‡¦ç†ï¼ˆAPAå½¢å¼: Last, F. M.ï¼‰
    if authors != 'è‘—è€…ä¸æ˜':
        # ç°¡ç•¥åŒ–ï¼šå®Ÿéš›ã®APAå½¢å¼ã§ã¯å§“åã®é †åºå¤‰æ›´ãŒå¿…è¦
        author_formatted = authors
    else:
        author_formatted = 'è‘—è€…ä¸æ˜'
    
    # å¹´åº¦ã®å‡¦ç†
    year_formatted = f"({year})" if year != 'å¹´åº¦ä¸æ˜' else "(å¹´åº¦ä¸æ˜)"
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã®å‡¦ç†ï¼ˆAPAå½¢å¼ã§ã¯æ–‡ã®æœ€åˆã®å˜èªã®ã¿å¤§æ–‡å­—ï¼‰
    title_formatted = title
    
    # æ²è¼‰èªŒã®å‡¦ç†ï¼ˆã‚¤ã‚¿ãƒªãƒƒã‚¯ä½“ã‚’ç¤ºã™ãŸã‚*ã§å›²ã‚€ï¼‰
    venue_formatted = f"*{venue}*" if venue != 'æ²è¼‰èªŒä¸æ˜' else "*æ²è¼‰èªŒä¸æ˜*"
    
    # URLå‡¦ç†
    url_formatted = f" {url}" if url else ""
    
    # APAå½¢å¼ã®å¼•ç”¨æ–‡çŒ®ä½œæˆ
    citation = f"{author_formatted} {year_formatted}. {title_formatted}. {venue_formatted}.{url_formatted}"
    
    return citation

def format_bibtex_citation(paper, index):
    """BibTeXå½¢å¼ã§å¼•ç”¨æ–‡çŒ®ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    # å¿…è¦ãªæƒ…å ±ã‚’å–å¾—
    title = paper.get('title', 'Unknown Title')
    authors = paper.get('authors', 'Unknown Author')
    year = paper.get('year', 'Unknown')
    venue = paper.get('venue', 'Unknown Venue')
    url = paper.get('url', '')
    
    # BibTeXç”¨ã®ã‚­ãƒ¼ã‚’ç”Ÿæˆï¼ˆè‘—è€…ã®å§“+å¹´åº¦+ã‚¿ã‚¤ãƒˆãƒ«ã®æœ€åˆã®å˜èªï¼‰
    first_author = authors.split(',')[0].split()[-1] if authors != 'Unknown Author' else 'Unknown'
    first_word = title.split()[0] if title != 'Unknown Title' else 'Unknown'
    bibtex_key = f"{first_author}{year}{first_word}".replace(' ', '').replace(',', '')
    
    # è‘—è€…åã‚’BibTeXå½¢å¼ã«å¤‰æ›ï¼ˆLast, First and Last, Firstï¼‰
    if authors != 'Unknown Author':
        author_list = [author.strip() for author in authors.split(',')]
        bibtex_authors = ' and '.join(author_list)
    else:
        bibtex_authors = 'Unknown Author'
    
    # è«–æ–‡ã®ç¨®é¡ã‚’åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
    venue_lower = venue.lower() if venue != 'Unknown Venue' else ''
    if any(word in venue_lower for word in ['conference', 'proceedings', 'workshop', 'symposium']):
        entry_type = 'inproceedings'
        venue_field = 'booktitle'
    elif any(word in venue_lower for word in ['journal', 'transactions', 'letters']):
        entry_type = 'article'
        venue_field = 'journal'
    else:
        entry_type = 'misc'
        venue_field = 'howpublished'
    
    # BibTeXå½¢å¼ã®æ–‡çŒ®æƒ…å ±ã‚’ä½œæˆ
    bibtex_entry = f"""@{entry_type}{{{bibtex_key},
  title = {{{title}}},
  author = {{{bibtex_authors}}},
  {venue_field} = {{{venue}}},
  year = {{{year}}}"""
    
    # URLãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    if url:
        bibtex_entry += f",\n  url = {{{url}}}"
    
    # æŠ„éŒ²ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    abstract = paper.get('abstract', '')
    if abstract and abstract != 'æŠ„éŒ²ãªã—' and len(abstract) > 10:
        # æŠ„éŒ²ã‚’é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
        clean_abstract = abstract.replace('{', '\\{').replace('}', '\\}').replace('%', '\\%')
        bibtex_entry += f",\n  abstract = {{{clean_abstract}}}"
    
    bibtex_entry += "\n}"
    
    return bibtex_entry

def create_csv_data(papers, search_query):
    """æ¤œç´¢çµæœã‚’CSVå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
    csv_data = []
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
    headers = [
        'No.', 'ã‚¿ã‚¤ãƒˆãƒ«', 'è‘—è€…', 'å¹´åº¦', 'æ²è¼‰èªŒ', 'å¼•ç”¨æ•°', 
        'æŠ„éŒ²', 'URL', 'APAå¼•ç”¨å½¢å¼', 'æ¤œç´¢èª', 'æ¤œç´¢æ—¥æ™‚', 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'
    ]
    csv_data.append(headers)
    
    # ãƒ‡ãƒ¼ã‚¿è¡Œ
    search_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    for i, paper in enumerate(papers, 1):
        row = [
            i,
            paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜'),
            paper.get('authors', 'è‘—è€…ä¸æ˜'),
            paper.get('year', 'å¹´åº¦ä¸æ˜'),
            paper.get('venue', 'æ²è¼‰èªŒä¸æ˜'),
            paper.get('citation_count', 0),
            paper.get('abstract', 'æŠ„éŒ²ãªã—'),
            paper.get('url', ''),
            format_apa_citation(paper),
            search_query,
            search_datetime,
            paper.get('source', 'Unknown')
        ]
        csv_data.append(row)
    
    return csv_data

def create_csv_download(papers, search_query):
    """CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    csv_data = create_csv_data(papers, search_query)
    
    # StringIOã‚’ä½¿ç”¨ã—ã¦CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerows(csv_data)
    
    return output.getvalue()

def create_bibtex_data(papers):
    """ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã‚’BibTeXå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
    bibtex_entries = []
    
    for i, paper in enumerate(papers, 1):
        bibtex_entry = format_bibtex_citation(paper, i)
        bibtex_entries.append(bibtex_entry)
    
    # BibTeXå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
    header = f"""% BibTeX bibliography file
% Generated by EduStudy Academic Paper Search Tool
% Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
% Total entries: {len(papers)}

"""
    
    return header + '\n\n'.join(bibtex_entries)

def display_paper_with_save(paper, search_query, index):
    """è«–æ–‡æƒ…å ±ã‚’ä¿å­˜ãƒœã‚¿ãƒ³ä»˜ãã§è¡¨ç¤ºã™ã‚‹é–¢æ•°"""
    with st.container():
        title = str(paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜'))
        highlighted_title = highlight_text(title, search_query)
        
        source = paper.get('source', 'Unknown')
        source_emoji = "ğŸ“" if source == "Semantic Scholar" else "ğŸ“š" if source == "Google Scholar" else "ğŸ”"
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ä¿å­˜ãƒœã‚¿ãƒ³ã‚’åŒã˜è¡Œã«é…ç½®
        col1, col2 = st.columns([5, 1])
        with col1:
            st.markdown(f"### {index}. {highlighted_title}", unsafe_allow_html=True)
            st.markdown(f"**{source_emoji} ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:** {source}")
        with col2:
            # å€‹åˆ¥ä¿å­˜ãƒœã‚¿ãƒ³
            save_key = f"save_{index}_{hash(title)}"
            if st.button("ğŸ’¾", key=save_key, help="ã“ã®è«–æ–‡ã‚’ä¿å­˜"):
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                existing_titles = [p.get('title') for p in st.session_state.saved_papers]
                if title not in existing_titles:
                    st.session_state.saved_papers.append(paper)
                    st.success("è«–æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                    st.rerun()
                else:
                    st.warning("ã“ã®è«–æ–‡ã¯æ—¢ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")
        
        # è‘—è€…æƒ…å ±ã¨å¹´åº¦
        col1, col2, col3 = st.columns([3, 1, 1])
        with col1:
            authors = str(paper.get('authors', 'è‘—è€…ä¸æ˜'))
            st.markdown(f"**è‘—è€…:** {authors}")
        with col2:
            year = paper.get('year', 'å¹´åº¦ä¸æ˜')
            st.markdown(f"**å¹´åº¦:** {year}")
        with col3:
            citation_count = paper.get('citation_count', 0)
            st.markdown(f"**å¼•ç”¨æ•°:** {citation_count}")
        
        # æ²è¼‰èªŒæƒ…å ±
        venue = paper.get('venue')
        if venue and venue != 'æ²è¼‰èªŒä¸æ˜':
            st.markdown(f"**æ²è¼‰èªŒ:** {str(venue)}")
        
        # APAå¼•ç”¨å½¢å¼ã‚’è¡¨ç¤º
        apa_citation = format_apa_citation(paper)
        bibtex_citation = format_bibtex_citation(paper, index)
        
        col1, col2 = st.columns(2)
        with col1:
            with st.expander("ğŸ“ APAå¼•ç”¨å½¢å¼"):
                st.code(apa_citation, language="text")
        with col2:
            with st.expander("ğŸ“š BibTeXå¼•ç”¨å½¢å¼"):
                st.code(bibtex_citation, language="bibtex")
        
        # æŠ„éŒ²ï¼ˆãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãï¼‰
        abstract = paper.get('abstract')
        if abstract and abstract != 'æŠ„éŒ²ãªã—' and abstract != 'None':
            abstract_str = str(abstract)
            # æŠ„éŒ²ã‚’é©åˆ‡ãªé•·ã•ã«åˆ¶é™
            if len(abstract_str) > 300:
                truncated_abstract = abstract_str[:300] + "..."
                highlighted_abstract = highlight_text(truncated_abstract, search_query)
            else:
                highlighted_abstract = highlight_text(abstract_str, search_query)
            st.markdown(f"**æŠ„éŒ²:** {highlighted_abstract}", unsafe_allow_html=True)
        
        # è«–æ–‡ãƒªãƒ³ã‚¯
        url = paper.get('url')
        if url and url != '':
            st.markdown(f"[ğŸ“„ è«–æ–‡ã‚’èª­ã‚€]({url})")
        
        st.markdown("---")

def main():
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title="EduStudy - æ•™è‚²è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ",
        page_icon="ğŸ“",
        layout="wide"
    )
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
    }
    .search-box {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .paper-card {
        background: white;
        padding: 1.5rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    .search-tip {
        background: #e8f5e8;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #4caf50;
        margin-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'saved_papers' not in st.session_state:
        st.session_state.saved_papers = []
    if 'last_search_query' not in st.session_state:
        st.session_state.last_search_query = ""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“ EduStudy - æ•™è‚²è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ </h1>
        <p>ä¸–ç•Œä¸­ã®æ•™è‚²é–¢ä¿‚è«–æ–‡ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œç´¢ã§ãã¾ã™ã€‚Semantic Scholar APIã‚’ä½¿ç”¨ã—ã¦æœ€æ–°ã®ç ”ç©¶æˆæœã‚’æä¾›ã—ã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ” æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹")
        st.info("ğŸ“ Semantic Scholar API\n200M+ã®å­¦è¡“è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
        
        # æ¤œç´¢çµæœæ•°ã®è¨­å®š
        result_limit = st.slider(
            "æ¤œç´¢çµæœæ•°",
            min_value=5,
            max_value=100,
            value=20,
            step=5
        )
        
        # å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        current_year = datetime.now().year
        year_range = st.slider(
            "ç™ºè¡Œå¹´åº¦ç¯„å›²",
            min_value=1950,
            max_value=current_year,
            value=(2020, current_year),
            step=1
        )
        
        st.markdown("---")
        
        st.header("ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸè«–æ–‡")
        
        if st.session_state.saved_papers:
            st.success(f"ä¿å­˜æ¸ˆã¿: {len(st.session_state.saved_papers)}ä»¶")
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            if st.button("ğŸ“¥ CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", use_container_width=True):
                csv_content = create_csv_download(
                    st.session_state.saved_papers, 
                    st.session_state.last_search_query
                )
                
                filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                
                st.download_button(
                    label="ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_content,
                    file_name=filename,
                    mime="text/csv",
                    use_container_width=True
                )
            
            # BibTeXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            if st.button("ğŸ“š BibTeXå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", use_container_width=True):
                bibtex_content = create_bibtex_data(st.session_state.saved_papers)
                
                filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.bib"
                
                st.download_button(
                    label="ğŸ“– BibTeXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=bibtex_content,
                    file_name=filename,
                    mime="text/plain",
                    use_container_width=True
                )
            
            # ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
            if st.button("ğŸ—‘ï¸ ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
                st.session_state.saved_papers = []
                st.success("ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                st.rerun()
            
            # ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã®ä¸€è¦§è¡¨ç¤º
            with st.expander("ğŸ“‹ ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ä¸€è¦§"):
                for i, paper in enumerate(st.session_state.saved_papers, 1):
                    st.write(f"{i}. {paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')}")
                    st.write(f"   è‘—è€…: {paper.get('authors', 'è‘—è€…ä¸æ˜')}")
                    st.write(f"   å¹´åº¦: {paper.get('year', 'å¹´åº¦ä¸æ˜')}")
                    st.write("---")
        else:
            st.info("ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        st.markdown("---")
        
        st.markdown("**ğŸ’¡ æ¤œç´¢ã®ãƒ’ãƒ³ãƒˆ:**")
        st.markdown('- å¼•ç”¨ç¬¦ã§å›²ã‚€ã¨å®Œå…¨ä¸€è‡´: `"machine learning"`')
        st.markdown("- è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: `AI education deep learning`")
        st.markdown("- æ—¥è‹±å¯¾å¿œ")
        st.markdown("- æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã«ç‰¹åŒ–")
        st.markdown("- å¼•ç”¨æ•°ã®å¤šã„è«–æ–‡ãŒä¸Šä½è¡¨ç¤º")
    
    # ãƒ¡ã‚¤ãƒ³æ¤œç´¢ã‚¨ãƒªã‚¢
    st.markdown('<div class="search-box">', unsafe_allow_html=True)
    
    # æ¤œç´¢ã®ãƒ’ãƒ³ãƒˆè¡¨ç¤º
    st.markdown("""
    <div class="search-tip">
        <strong>ğŸ” æ¤œç´¢ã®ã‚³ãƒ„:</strong><br>
        â€¢ <strong>å®Œå…¨ä¸€è‡´æ¤œç´¢:</strong> "Generative AI" ã®ã‚ˆã†ã«å¼•ç”¨ç¬¦ã§å›²ã‚€ã¨ã€ã‚¹ãƒšãƒ¼ã‚¹ã‚’å«ã‚€èªå¥ã‚’å®Œå…¨ä¸€è‡´ã§æ¤œç´¢<br>
        â€¢ <strong>è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:</strong> machine learning education ã®ã‚ˆã†ã«è¤‡æ•°ã®èªã‚’çµ„ã¿åˆã‚ã›å¯èƒ½<br>
        â€¢ <strong>æ—¥è‹±å¯¾å¿œ:</strong> æ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ã§æ¤œç´¢ã§ãã¾ã™
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([4, 1])
    
    with col1:
        search_query = st.text_input(
            "ğŸ” æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder='ä¾‹: "collaborative learning", AIæ•™è‚², ãƒ‡ã‚¸ã‚¿ãƒ«æ•™æ',
            help='å¼•ç”¨ç¬¦ã§å›²ã‚€ã¨å®Œå…¨ä¸€è‡´æ¤œç´¢ã€‚è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›å¯èƒ½ã€‚'
        )
    
    with col2:
        search_button = st.button("ğŸš€ æ¤œç´¢é–‹å§‹", type="primary", use_container_width=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # æ¤œç´¢å®Ÿè¡Œéƒ¨åˆ†
    if search_query and (search_button or search_query):
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ä¿å­˜
        st.session_state.last_search_query = search_query
        
        with st.spinner("ğŸ” è«–æ–‡ã‚’æ¤œç´¢ä¸­..."):
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("Semantic Scholar APIã«æ¥ç¶šä¸­...")
            progress_bar.progress(25)
            
            results = search_papers_api(search_query, result_limit)
            
            progress_bar.progress(75)
            
            # å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if results:
                filtered_results = [
                    paper for paper in results 
                    if paper['year'] != 'å¹´åº¦ä¸æ˜' and 
                    isinstance(paper['year'], int) and 
                    year_range[0] <= paper['year'] <= year_range[1]
                ]
                results = filtered_results
            
            progress_bar.progress(100)
            status_text.text("æ¤œç´¢å®Œäº†!")
            time.sleep(0.5)
            progress_bar.empty()
            status_text.empty()
        
        # çµæœè¡¨ç¤º
        st.markdown(f"## ğŸ“Š æ¤œç´¢çµæœ: {len(results)}ä»¶")
        
        if results:
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ğŸ“ Semantic Scholar", len(results))
            with col2:
                avg_citations = sum(paper.get('citation_count', 0) for paper in results) / len(results)
                st.metric("ğŸ“ˆ å¹³å‡å¼•ç”¨æ•°", f"{avg_citations:.1f}")
        
        if results:
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ’¾ å…¨ã¦ã®çµæœã‚’ä¿å­˜", type="secondary"):
                    # é‡è¤‡ã‚’é¿ã‘ã¦ä¿å­˜
                    new_papers = []
                    existing_titles = [p.get('title') for p in st.session_state.saved_papers]
                    
                    for paper in results:
                        if paper.get('title') not in existing_titles:
                            new_papers.append(paper)
                    
                    st.session_state.saved_papers.extend(new_papers)
                    st.success(f"{len(new_papers)}ä»¶ã®æ–°ã—ã„è«–æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
                    st.rerun()
            
            with col2:
                if st.session_state.saved_papers:
                    download_format = st.selectbox(
                        "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å½¢å¼",
                        ["CSV", "BibTeX"],
                        key="download_format_main"
                    )
                    
                    if download_format == "CSV":
                        csv_content = create_csv_download(
                            st.session_state.saved_papers, 
                            search_query
                        )
                        filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                        mime_type = "text/csv"
                        file_content = csv_content
                        button_label = "ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                    else:  # BibTeX
                        bibtex_content = create_bibtex_data(st.session_state.saved_papers)
                        filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.bib"
                        mime_type = "text/plain"
                        file_content = bibtex_content
                        button_label = "ğŸ“š BibTeXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                    
                    st.download_button(
                        label=button_label,
                        data=file_content,
                        file_name=filename,
                        mime=mime_type,
                        type="primary"
                    )
            
            # å„è«–æ–‡ã®è¡¨ç¤º
            for i, paper in enumerate(results, 1):
                display_paper_with_save(paper, search_query, i)
                
        else:
            st.warning("ğŸ” æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.markdown("""
            **ğŸ’¡ æ¤œç´¢ã®ã‚³ãƒ„:**
            - ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã¿ã¦ãã ã•ã„
            - è‹±èªã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚è©¦ã—ã¦ã¿ã¦ãã ã•ã„
            - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ•°ã‚’æ¸›ã‚‰ã—ã¦ã¿ã¦ãã ã•ã„
            - å¹´åº¦ç¯„å›²ã‚’åºƒã’ã¦ã¿ã¦ãã ã•ã„
            - å¼•ç”¨ç¬¦ã‚’ä½¿ã£ãŸå®Œå…¨ä¸€è‡´æ¤œç´¢ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„
            """)
    
    else:
        # åˆæœŸè¡¨ç¤ºï¼šã‚·ã‚¹ãƒ†ãƒ èª¬æ˜
        st.markdown("## ğŸ¯ EduStudyã«ã¤ã„ã¦")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ğŸ” æ¤œç´¢æ©Ÿèƒ½
            - **é«˜ç²¾åº¦æ¤œç´¢**: Semantic Scholar APIã«ã‚ˆã‚‹200M+è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            - **å®Œå…¨ä¸€è‡´æ¤œç´¢**: å¼•ç”¨ç¬¦ã§å›²ã‚“ã èªå¥ã®å®Œå…¨ä¸€è‡´æ¤œç´¢
            - **å¤šè¨€èªå¯¾å¿œ**: æ—¥æœ¬èªãƒ»è‹±èªã§ã®æ¤œç´¢ãŒå¯èƒ½
            - **æ•™è‚²ç‰¹åŒ–**: æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã«ç‰¹åŒ–ã—ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            - **ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º**: æ¤œç´¢èªã‚’çµæœå†…ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            """)
            
        with col2:
            st.markdown("""
            ### ğŸ“Š æ©Ÿèƒ½
            - **è«–æ–‡ä¿å­˜**: æ°—ã«ãªã‚‹è«–æ–‡ã‚’å€‹åˆ¥ã¾ãŸã¯ä¸€æ‹¬ä¿å­˜
            - **APAå¼•ç”¨**: APA ver.7å½¢å¼ã®å¼•ç”¨æ–‡çŒ®ã‚’è‡ªå‹•ç”Ÿæˆ
            - **BibTeXå‡ºåŠ›**: Zoteroã‚„Mendeleyã§èª­ã¿è¾¼ã¿å¯èƒ½
            - **CSVå‡ºåŠ›**: æ¤œç´¢çµæœã‚’CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            - **å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿**: ç™ºè¡Œå¹´åº¦ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿æ¤œç´¢
            """)
        
        st.markdown("---")
        
        st.markdown("""
        ### ğŸš€ ä½¿ã„æ–¹
        1. **æ¤œç´¢èªå…¥åŠ›**: ä¸Šã®æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã«é–¢å¿ƒã®ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›
        2. **å®Œå…¨ä¸€è‡´æ¤œç´¢**: "machine learning"ã®ã‚ˆã†ã«å¼•ç”¨ç¬¦ã§å›²ã‚€ã¨å®Œå…¨ä¸€è‡´
        3. **ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¤œç´¢çµæœæ•°ã‚„å¹´åº¦ç¯„å›²ã‚’èª¿æ•´
        4. **æ¤œç´¢å®Ÿè¡Œ**: ã€Œæ¤œç´¢é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        5. **çµæœç¢ºèª**: ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã•ã‚ŒãŸæ¤œç´¢çµæœã‚’ç¢ºèª
        6. **è«–æ–‡ä¿å­˜**: ğŸ’¾ãƒœã‚¿ãƒ³ã§è«–æ–‡ã‚’ä¿å­˜ã—ã€CSV/BibTeXå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        """)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray; font-size: 0.8em; padding: 2rem;'>
        <p>ğŸ“ EduStudy - æ•™è‚²è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ </p>
        <p>Powered by Semantic Scholar API | ãƒ‡ãƒ¼ã‚¿ã¯å®šæœŸçš„ã«æ›´æ–°ã•ã‚Œã¾ã™</p>
        <p>ğŸ”¬ ç ”ç©¶è€…ã®çš†æ§˜ã®å­¦è¡“æ´»å‹•ã‚’æ”¯æ´ã—ã¾ã™</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
