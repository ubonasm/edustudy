import streamlit as st
import requests
import re
from datetime import datetime
import time
import csv
import io

try:
    from scholarly import scholarly
    GOOGLE_SCHOLAR_AVAILABLE = True
except ImportError:
    GOOGLE_SCHOLAR_AVAILABLE = False

def search_papers_api(query, limit=20):
    """Semantic Scholar APIã‚’ä½¿ç”¨ã—ã¦è«–æ–‡ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
    if not query:
        return []
    
    time.sleep(1)  # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã«1ç§’å¾…æ©Ÿ
    
    # Semantic Scholar API endpoint
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    
    # æ•™è‚²é–¢ä¿‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Š
    education_keywords = ["education", "learning", "teaching", "pedagogy", "educational"]
    enhanced_query = f"{query} {' OR '.join(education_keywords)}"
    
    params = {
        'query': enhanced_query,
        'limit': limit,
        'fields': 'paperId,title,authors,year,abstract,venue,citationCount,publicationDate,url'
    }
    
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            headers = {
                'User-Agent': 'Academic Paper Search Tool (educational use)',
                'Accept': 'application/json'
            }
            
            response = requests.get(base_url, params=params, headers=headers, timeout=15)
            
            if response.status_code == 429:
                if attempt < max_retries - 1:
                    wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    st.warning(f"APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    st.error("APIåˆ¶é™ã«ã‚ˆã‚Šæ¤œç´¢ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                    return []
            
            response.raise_for_status()
            data = response.json()
            
            papers = []
            for paper in data.get('data', []):
                # æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                title = paper.get('title') or ''
                abstract = paper.get('abstract') or ''
                title_abstract = (title + ' ' + abstract).lower()
                education_terms = ['education', 'learning', 'teaching', 'student', 'school', 'classroom', 'pedagogy', 'curriculum', 'instruction']
                
                if any(term in title_abstract for term in education_terms):
                    authors_list = paper.get('authors', [])
                    if authors_list:
                        authors_names = []
                        for author in authors_list:
                            if author and isinstance(author, dict):
                                name = author.get('name')
                                if name:
                                    authors_names.append(str(name))
                        authors_str = ', '.join(authors_names) if authors_names else 'è‘—è€…ä¸æ˜'
                    else:
                        authors_str = 'è‘—è€…ä¸æ˜'
                    
                    processed_paper = {
                        'title': str(title) if title else 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜',
                        'authors': authors_str,
                        'year': paper.get('year') if paper.get('year') is not None else 'å¹´åº¦ä¸æ˜',
                        'abstract': str(abstract) if abstract else 'æŠ„éŒ²ãªã—',
                        'venue': str(paper.get('venue')) if paper.get('venue') else 'æ²è¼‰èªŒä¸æ˜',
                        'citation_count': paper.get('citationCount', 0) or 0,
                        'url': str(paper.get('url')) if paper.get('url') else '',
                        'publication_date': str(paper.get('publicationDate')) if paper.get('publicationDate') else '',
                        'source': 'Semantic Scholar'  # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
                    }
                    papers.append(processed_paper)
            
            return papers
        
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                st.warning(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚{retry_delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
                continue
            else:
                st.error(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.info("ğŸ’¡ è§£æ±ºæ–¹æ³•: ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã¯æ¤œç´¢èªã‚’å¤‰æ›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
                return []
        except Exception as e:
            st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    return []

def search_google_scholar(query, limit=10):
    """Google Scholarã‚’ä½¿ç”¨ã—ã¦è«–æ–‡ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
    if not GOOGLE_SCHOLAR_AVAILABLE:
        return []
    
    if not query:
        return []
    
    papers = []
    try:
        # Google Scholaræ¤œç´¢ã‚’å®Ÿè¡Œ
        search_query = scholarly.search_pubs(query)
        
        count = 0
        for paper in search_query:
            if count >= limit:
                break
            
            try:
                # è«–æ–‡æƒ…å ±ã‚’å–å¾—
                title = paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
                authors = ', '.join([author['name'] for author in paper.get('author', [])]) if paper.get('author') else 'è‘—è€…ä¸æ˜'
                year = paper.get('year', 'å¹´åº¦ä¸æ˜')
                abstract = paper.get('abstract', 'æŠ„éŒ²ãªã—')
                venue = paper.get('venue', 'æ²è¼‰èªŒä¸æ˜')
                citation_count = paper.get('num_citations', 0)
                url = paper.get('pub_url', '')
                
                # æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                title_abstract = (str(title) + ' ' + str(abstract)).lower()
                education_terms = ['education', 'learning', 'teaching', 'student', 'school', 'classroom', 'pedagogy', 'curriculum', 'instruction']
                
                if any(term in title_abstract for term in education_terms):
                    processed_paper = {
                        'title': str(title) if title else 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜',
                        'authors': str(authors) if authors else 'è‘—è€…ä¸æ˜',
                        'year': int(year) if str(year).isdigit() else 'å¹´åº¦ä¸æ˜',
                        'abstract': str(abstract) if abstract else 'æŠ„éŒ²ãªã—',
                        'venue': str(venue) if venue else 'æ²è¼‰èªŒä¸æ˜',
                        'citation_count': int(citation_count) if citation_count else 0,
                        'url': str(url) if url else '',
                        'publication_date': '',
                        'source': 'Google Scholar'  # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
                    }
                    papers.append(processed_paper)
                    count += 1
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                time.sleep(2)
                
            except Exception as e:
                st.warning(f"Google Scholarè«–æ–‡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                continue
                
    except Exception as e:
        st.error(f"Google Scholaræ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []
    
    return papers

def search_combined(query, limit_per_source=10):
    """è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰è«–æ–‡ã‚’æ¤œç´¢ã—ã¦çµåˆã™ã‚‹é–¢æ•°"""
    all_papers = []
    
    # Semantic Scholaræ¤œç´¢
    st.info("ğŸ” Semantic Scholarã§æ¤œç´¢ä¸­...")
    semantic_papers = search_papers_api(query, limit_per_source)
    for paper in semantic_papers:
        paper['source'] = 'Semantic Scholar'
    all_papers.extend(semantic_papers)
    
    # Google Scholaræ¤œç´¢ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    if GOOGLE_SCHOLAR_AVAILABLE:
        st.info("ğŸ” Google Scholarã§æ¤œç´¢ä¸­...")
        try:
            google_papers = search_google_scholar(query, limit_per_source)
            all_papers.extend(google_papers)
        except Exception as e:
            st.warning(f"Google Scholaræ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    else:
        st.warning("Google Scholaræ¤œç´¢ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆscholarlyãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ï¼‰")
    
    # é‡è¤‡é™¤å»ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
    seen_titles = set()
    unique_papers = []
    for paper in all_papers:
        title_lower = paper.get('title', '').lower().strip()
        if title_lower and title_lower not in seen_titles:
            seen_titles.add(title_lower)
            unique_papers.append(paper)
    
    # å¼•ç”¨æ•°ã§ã‚½ãƒ¼ãƒˆ
    unique_papers.sort(key=lambda x: x.get('citation_count', 0), reverse=True)
    
    return unique_papers

def highlight_text(text, search_terms):
    """æ¤œç´¢èªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹é–¢æ•°"""
    if not search_terms or not text or text == 'None':
        return str(text) if text else ''
    
    # æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦å®‰å…¨ã«å‡¦ç†
    text = str(text)
    search_terms = str(search_terms)
    
    # è¤‡æ•°ã®æ¤œç´¢èªã«å¯¾å¿œ
    terms = [term.strip() for term in search_terms.split() if term.strip()]
    highlighted_text = text
    
    for term in terms:
        if term:  # ç©ºæ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯
            # å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„æ¤œç´¢
            pattern = re.compile(re.escape(term), re.IGNORECASE)
            highlighted_text = pattern.sub(
                f'<mark style="background-color: #ffeb3b; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{term}</mark>',
                highlighted_text
            )
    
    return highlighted_text

def format_apa_citation(paper):
    """APA ver.7å½¢å¼ã§å¼•ç”¨æ–‡çŒ®ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    authors = paper.get('authors', 'è‘—è€…ä¸æ˜')
    year = paper.get('year', 'å¹´åº¦ä¸æ˜')
    title = paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
    venue = paper.get('venue', 'æ²è¼‰èªŒä¸æ˜')
    url = paper.get('url', '')
    
    # è‘—è€…åã®å‡¦ç†ï¼ˆAPAå½¢å¼: Last, F. M.ï¼‰
    if authors != 'è‘—è€…ä¸æ˜':
        # ç°¡ç•¥åŒ–ï¼šå®Ÿéš›ã®APAå½¢å¼ã§ã¯å§“åã®é †åºå¤‰æ›´ãŒå¿…è¦
        author_formatted = authors
    else:
        author_formatted = 'è‘—è€…ä¸æ˜'
    
    # å¹´åº¦ã®å‡¦ç†
    year_formatted = f"({year})" if year != 'å¹´åº¦ä¸æ˜' else "(å¹´åº¦ä¸æ˜)"
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã®å‡¦ç†ï¼ˆAPAå½¢å¼ã§ã¯æ–‡ã®æœ€åˆã®å˜èªã®ã¿å¤§æ–‡å­—ï¼‰
    title_formatted = title
    
    # æ²è¼‰èªŒã®å‡¦ç†ï¼ˆã‚¤ã‚¿ãƒªãƒƒã‚¯ä½“ã‚’ç¤ºã™ãŸã‚*ã§å›²ã‚€ï¼‰
    venue_formatted = f"*{venue}*" if venue != 'æ²è¼‰èªŒä¸æ˜' else "*æ²è¼‰èªŒä¸æ˜*"
    
    # URLå‡¦ç†
    url_formatted = f" {url}" if url else ""
    
    # APAå½¢å¼ã®å¼•ç”¨æ–‡çŒ®ä½œæˆ
    citation = f"{author_formatted} {year_formatted}. {title_formatted}. {venue_formatted}.{url_formatted}"
    
    return citation

def format_bibtex_citation(paper, index):
    """BibTeXå½¢å¼ã§å¼•ç”¨æ–‡çŒ®ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    # å¿…è¦ãªæƒ…å ±ã‚’å–å¾—
    title = paper.get('title', 'Unknown Title')
    authors = paper.get('authors', 'Unknown Author')
    year = paper.get('year', 'Unknown')
    venue = paper.get('venue', 'Unknown Venue')
    url = paper.get('url', '')
    
    # BibTeXç”¨ã®ã‚­ãƒ¼ã‚’ç”Ÿæˆï¼ˆè‘—è€…ã®å§“+å¹´åº¦+ã‚¿ã‚¤ãƒˆãƒ«ã®æœ€åˆã®å˜èªï¼‰
    first_author = authors.split(',')[0].split()[-1] if authors != 'Unknown Author' else 'Unknown'
    first_word = title.split()[0] if title != 'Unknown Title' else 'Unknown'
    bibtex_key = f"{first_author}{year}{first_word}".replace(' ', '').replace(',', '')
    
    # è‘—è€…åã‚’BibTeXå½¢å¼ã«å¤‰æ›ï¼ˆLast, First and Last, Firstï¼‰
    if authors != 'Unknown Author':
        author_list = [author.strip() for author in authors.split(',')]
        bibtex_authors = ' and '.join(author_list)
    else:
        bibtex_authors = 'Unknown Author'
    
    # è«–æ–‡ã®ç¨®é¡ã‚’åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
    venue_lower = venue.lower() if venue != 'Unknown Venue' else ''
    if any(word in venue_lower for word in ['conference', 'proceedings', 'workshop', 'symposium']):
        entry_type = 'inproceedings'
        venue_field = 'booktitle'
    elif any(word in venue_lower for word in ['journal', 'transactions', 'letters']):
        entry_type = 'article'
        venue_field = 'journal'
    else:
        entry_type = 'misc'
        venue_field = 'howpublished'
    
    # BibTeXå½¢å¼ã®æ–‡çŒ®æƒ…å ±ã‚’ä½œæˆ
    bibtex_entry = f"""@{entry_type}{{{bibtex_key},
  title = {{{title}}},
  author = {{{bibtex_authors}}},
  {venue_field} = {{{venue}}},
  year = {{{year}}}"""
    
    # URLãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    if url:
        bibtex_entry += f",\n  url = {{{url}}}"
    
    # æŠ„éŒ²ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    abstract = paper.get('abstract', '')
    if abstract and abstract != 'æŠ„éŒ²ãªã—' and len(abstract) > 10:
        # æŠ„éŒ²ã‚’é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
        clean_abstract = abstract.replace('{', '\\{').replace('}', '\\}').replace('%', '\\%')
        bibtex_entry += f",\n  abstract = {{{clean_abstract}}}"
    
    bibtex_entry += "\n}"
    
    return bibtex_entry

def create_csv_data(papers, search_query):
    """æ¤œç´¢çµæœã‚’CSVå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
    csv_data = []
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
    headers = [
        'No.', 'title', 'author', 'year', 'journal', 'cites', 
        'abstract', 'URL', 'APA style', 'search words', 'search date', 'data sources'
    ]
    csv_data.append(headers)
    
    # ãƒ‡ãƒ¼ã‚¿è¡Œ
    search_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    for i, paper in enumerate(papers, 1):
        row = [
            i,
            paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜'),
            paper.get('authors', 'è‘—è€…ä¸æ˜'),
            paper.get('year', 'å¹´åº¦ä¸æ˜'),
            paper.get('venue', 'æ²è¼‰èªŒä¸æ˜'),
            paper.get('citation_count', 0),
            paper.get('abstract', 'æŠ„éŒ²ãªã—'),
            paper.get('url', ''),
            format_apa_citation(paper),
            search_query,
            search_datetime,
            paper.get('source', 'Unknown')
        ]
        csv_data.append(row)
    
    return csv_data

def create_csv_download(papers, search_query):
    """CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    csv_data = create_csv_data(papers, search_query)
    
    # StringIOã‚’ä½¿ç”¨ã—ã¦CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerows(csv_data)
    
    return output.getvalue()

def create_bibtex_data(papers):
    """ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã‚’BibTeXå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
    bibtex_entries = []
    
    for i, paper in enumerate(papers, 1):
        bibtex_entry = format_bibtex_citation(paper, i)
        bibtex_entries.append(bibtex_entry)
    
    # BibTeXå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
    header = f"""% BibTeX bibliography file
% Generated by Academic Paper Search Tool
% Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
% Total entries: {len(papers)}

"""
    
    return header + '\n\n'.join(bibtex_entries)

def display_paper_with_save(paper, search_query, index):
    """è«–æ–‡æƒ…å ±ã‚’ä¿å­˜ãƒœã‚¿ãƒ³ä»˜ãã§è¡¨ç¤ºã™ã‚‹é–¢æ•°"""
    with st.container():
        title = str(paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜'))
        highlighted_title = highlight_text(title, search_query)
        
        source = paper.get('source', 'Unknown')
        source_emoji = "ğŸ“" if source == "Semantic Scholar" else "ğŸ“š" if source == "Google Scholar" else "ğŸ”"
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ä¿å­˜ãƒœã‚¿ãƒ³ã‚’åŒã˜è¡Œã«é…ç½®
        col1, col2 = st.columns([5, 1])
        with col1:
            st.markdown(f"### {index}. {highlighted_title}", unsafe_allow_html=True)
            st.markdown(f"**{source_emoji} ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:** {source}")
        with col2:
            # å€‹åˆ¥ä¿å­˜ãƒœã‚¿ãƒ³
            save_key = f"save_{index}_{hash(title)}"
            if st.button("ğŸ’¾", key=save_key, help="ã“ã®è«–æ–‡ã‚’ä¿å­˜"):
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                existing_titles = [p.get('title') for p in st.session_state.saved_papers]
                if title not in existing_titles:
                    st.session_state.saved_papers.append(paper)
                    st.success("è«–æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                    st.rerun()
                else:
                    st.warning("ã“ã®è«–æ–‡ã¯æ—¢ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")
        
        # è‘—è€…æƒ…å ±ã¨å¹´åº¦
        col1, col2, col3 = st.columns([3, 1, 1])
        with col1:
            authors = str(paper.get('authors', 'è‘—è€…ä¸æ˜'))
            st.markdown(f"**è‘—è€…:** {authors}")
        with col2:
            year = paper.get('year', 'å¹´åº¦ä¸æ˜')
            st.markdown(f"**å¹´åº¦:** {year}")
        with col3:
            citation_count = paper.get('citation_count', 0)
            st.markdown(f"**å¼•ç”¨æ•°:** {citation_count}")
        
        # æ²è¼‰èªŒæƒ…å ±
        venue = paper.get('venue')
        if venue and venue != 'æ²è¼‰èªŒä¸æ˜':
            st.markdown(f"**æ²è¼‰èªŒ:** {str(venue)}")
        
        # APAå¼•ç”¨å½¢å¼ã‚’è¡¨ç¤º
        apa_citation = format_apa_citation(paper)
        bibtex_citation = format_bibtex_citation(paper, index)
        
        col1, col2 = st.columns(2)
        with col1:
            with st.expander("ğŸ“ APAå¼•ç”¨å½¢å¼"):
                st.code(apa_citation, language="text")
        with col2:
            with st.expander("ğŸ“š BibTeXå¼•ç”¨å½¢å¼"):
                st.code(bibtex_citation, language="bibtex")
        
        # æŠ„éŒ²ï¼ˆãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãï¼‰
        abstract = paper.get('abstract')
        if abstract and abstract != 'æŠ„éŒ²ãªã—' and abstract != 'None':
            abstract_str = str(abstract)
            # æŠ„éŒ²ã‚’é©åˆ‡ãªé•·ã•ã«åˆ¶é™
            if len(abstract_str) > 300:
                truncated_abstract = abstract_str[:300] + "..."
                highlighted_abstract = highlight_text(truncated_abstract, search_query)
            else:
                highlighted_abstract = highlight_text(abstract_str, search_query)
            st.markdown(f"**æŠ„éŒ²:** {highlighted_abstract}", unsafe_allow_html=True)
        
        # è«–æ–‡ãƒªãƒ³ã‚¯
        url = paper.get('url')
        if url and url != '':
            st.markdown(f"[ğŸ“„ è«–æ–‡ã‚’èª­ã‚€]({url})")
        
        st.markdown("---")

def main():
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title="EduStudy - æ•™è‚²è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ",
        page_icon="ğŸ“",
        layout="wide"
    )
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
    }
    .search-box {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .paper-card {
        background: white;
        padding: 1.5rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    .source-badge {
        display: inline-block;
        padding: 0.25rem 0.5rem;
        background: #e3f2fd;
        border-radius: 12px;
        font-size: 0.8rem;
        margin-left: 0.5rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'saved_papers' not in st.session_state:
        st.session_state.saved_papers = []
    if 'last_search_query' not in st.session_state:
        st.session_state.last_search_query = ""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“ EduStudy - æ•™è‚²è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ </h1>
        <p>ä¸–ç•Œä¸­ã®æ•™è‚²é–¢ä¿‚è«–æ–‡ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œç´¢ã§ãã¾ã™ã€‚è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€æ–°ã®ç ”ç©¶æˆæœã‚’æä¾›ã—ã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ” æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹")
        use_semantic = st.checkbox("Semantic Scholar", value=True, help="200M+ã®å­¦è¡“è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
        use_google = st.checkbox("Google Scholar", value=GOOGLE_SCHOLAR_AVAILABLE, 
                                disabled=not GOOGLE_SCHOLAR_AVAILABLE,
                                help="Googleã®å­¦è¡“æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³" + ("" if GOOGLE_SCHOLAR_AVAILABLE else " (è¦scholarly)"))
        
        if not GOOGLE_SCHOLAR_AVAILABLE:
            st.info("ğŸ’¡ Google Scholaræ¤œç´¢ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ `pip install scholarly` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        # æ¤œç´¢çµæœæ•°ã®è¨­å®š
        result_limit = st.slider(
            "å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®æ¤œç´¢çµæœæ•°",
            min_value=5,
            max_value=100,
            value=10,
            step=5
        )
        
        # å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        current_year = datetime.now().year
        year_range = st.slider(
            "ç™ºè¡Œå¹´åº¦ç¯„å›²",
            min_value=1950,
            max_value=current_year,
            value=(2025, current_year),
            step=1
        )
        
        st.markdown("---")
        
        st.header("ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸè«–æ–‡")
        
        if st.session_state.saved_papers:
            st.success(f"ä¿å­˜æ¸ˆã¿: {len(st.session_state.saved_papers)}ä»¶")
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            if st.button("ğŸ“¥ CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", use_container_width=True):
                csv_content = create_csv_download(
                    st.session_state.saved_papers, 
                    st.session_state.last_search_query
                )
                
                filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                
                st.download_button(
                    label="ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_content,
                    file_name=filename,
                    mime="text/csv",
                    use_container_width=True
                )
            
            # BibTeXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            if st.button("ğŸ“š BibTeXå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", use_container_width=True):
                bibtex_content = create_bibtex_data(st.session_state.saved_papers)
                
                filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.bib"
                
                st.download_button(
                    label="ğŸ“– BibTeXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=bibtex_content,
                    file_name=filename,
                    mime="text/plain",
                    use_container_width=True
                )
            
            # ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
            if st.button("ğŸ—‘ï¸ ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
                st.session_state.saved_papers = []
                st.success("ä¿å­˜ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                st.rerun()
            
            # ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã®ä¸€è¦§è¡¨ç¤º
            with st.expander("ğŸ“‹ ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ä¸€è¦§"):
                for i, paper in enumerate(st.session_state.saved_papers, 1):
                    st.write(f"{i}. {paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')}")
                    st.write(f"   è‘—è€…: {paper.get('authors', 'è‘—è€…ä¸æ˜')}")
                    st.write(f"   å¹´åº¦: {paper.get('year', 'å¹´åº¦ä¸æ˜')}")
                    st.write("---")
        else:
            st.info("ä¿å­˜ã•ã‚ŒãŸè«–æ–‡ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        st.markdown("---")
        
        st.markdown("**ğŸ’¡ æ¤œç´¢ã®ãƒ’ãƒ³ãƒˆ:**")
        st.markdown("- æ—¥æœ¬èªã¾ãŸã¯è‹±èªã§æ¤œç´¢å¯èƒ½")
        st.markdown("- è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›")
        st.markdown("- æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã«ç‰¹åŒ–ã—ã¦æ¤œç´¢")
        st.markdown("- å¼•ç”¨æ•°ã®å¤šã„è«–æ–‡ãŒä¸Šä½ã«è¡¨ç¤º")
        
        st.markdown("---")
        st.markdown("**ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:**")
        if use_semantic:
            st.markdown("- âœ… Semantic Scholar API")
        if use_google and GOOGLE_SCHOLAR_AVAILABLE:
            st.markdown("- âœ… Google Scholar")
        if not use_semantic and not (use_google and GOOGLE_SCHOLAR_AVAILABLE):
            st.markdown("- âŒ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # ãƒ¡ã‚¤ãƒ³æ¤œç´¢ã‚¨ãƒªã‚¢
    st.markdown('<div class="search-box">', unsafe_allow_html=True)
    
    col1, col2 = st.columns([4, 1])
    
    with col1:
        search_query = st.text_input(
            "ğŸ” æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: ãƒ‡ã‚¸ã‚¿ãƒ«æ•™æ, collaborative learning, AI education",
            help="æ—¥æœ¬èªã¾ãŸã¯è‹±èªã§æ¤œç´¢ã§ãã¾ã™ã€‚è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        )
    
    with col2:
        search_button = st.button("ğŸš€ æ¤œç´¢é–‹å§‹", type="primary", use_container_width=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # æ¤œç´¢å®Ÿè¡Œ
    if search_query and (search_button or search_query):
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
        if not use_semantic and not (use_google and GOOGLE_SCHOLAR_AVAILABLE):
            st.error("âŒ æ¤œç´¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„")
            return
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ä¿å­˜
        st.session_state.last_search_query = search_query
        
        with st.spinner("ğŸ” è«–æ–‡ã‚’æ¤œç´¢ä¸­..."):
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            results = []
            
            if use_semantic:
                status_text.text("Semantic Scholar APIã«æ¥ç¶šä¸­...")
                progress_bar.progress(25)
                semantic_results = search_papers_api(search_query, result_limit)
                for paper in semantic_results:
                    paper['source'] = 'Semantic Scholar'
                results.extend(semantic_results)
                progress_bar.progress(50)
            
            if use_google and GOOGLE_SCHOLAR_AVAILABLE:
                status_text.text("Google Scholarã«æ¥ç¶šä¸­...")
                progress_bar.progress(75)
                try:
                    google_results = search_google_scholar(search_query, result_limit)
                    results.extend(google_results)
                except Exception as e:
                    st.warning(f"Google Scholaræ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            
            # é‡è¤‡é™¤å»ã¨ã‚½ãƒ¼ãƒˆ
            seen_titles = set()
            unique_results = []
            for paper in results:
                title_lower = paper.get('title', '').lower().strip()
                if title_lower and title_lower not in seen_titles:
                    seen_titles.add(title_lower)
                    unique_results.append(paper)
            
            # å¼•ç”¨æ•°ã§ã‚½ãƒ¼ãƒˆ
            unique_results.sort(key=lambda x: x.get('citation_count', 0), reverse=True)
            results = unique_results
            
            # å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if results:
                filtered_results = [
                    paper for paper in results 
                    if paper['year'] != 'å¹´åº¦ä¸æ˜' and 
                    isinstance(paper['year'], int) and 
                    year_range[0] <= paper['year'] <= year_range[1]
                ]
                results = filtered_results
            
            progress_bar.progress(100)
            status_text.text("æ¤œç´¢å®Œäº†!")
            time.sleep(0.5)
            progress_bar.empty()
            status_text.empty()
        
        # çµæœè¡¨ç¤º
        st.markdown(f"## ğŸ“Š æ¤œç´¢çµæœ: {len(results)}ä»¶")
        
        if results:
            source_counts = {}
            for paper in results:
                source = paper.get('source', 'Unknown')
                source_counts[source] = source_counts.get(source, 0) + 1
            
            col1, col2, col3 = st.columns(3)
            with col1:
                semantic_count = source_counts.get('Semantic Scholar', 0)
                st.metric("ğŸ“ Semantic Scholar", semantic_count)
            with col2:
                google_count = source_counts.get('Google Scholar', 0)
                st.metric("ğŸ“š Google Scholar", google_count)
            with col3:
                st.metric("ğŸ“Š é‡è¤‡é™¤å»å¾Œ", len(results))
        
        if results:
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ’¾ å…¨ã¦ã®çµæœã‚’ä¿å­˜", type="secondary"):
                    # é‡è¤‡ã‚’é¿ã‘ã¦ä¿å­˜
                    new_papers = []
                    existing_titles = [p.get('title') for p in st.session_state.saved_papers]
                    
                    for paper in results:
                        if paper.get('title') not in existing_titles:
                            new_papers.append(paper)
                    
                    st.session_state.saved_papers.extend(new_papers)
                    st.success(f"{len(new_papers)}ä»¶ã®æ–°ã—ã„è«–æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
                    st.rerun()
            
            with col2:
                if st.session_state.saved_papers:
                    download_format = st.selectbox(
                        "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å½¢å¼",
                        ["CSV", "BibTeX"],
                        key="download_format_main"
                    )
                    
                    if download_format == "CSV":
                        csv_content = create_csv_download(
                            st.session_state.saved_papers, 
                            search_query
                        )
                        filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                        mime_type = "text/csv"
                        file_content = csv_content
                        button_label = "ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                    else:  # BibTeX
                        bibtex_content = create_bibtex_data(st.session_state.saved_papers)
                        filename = f"è«–æ–‡æ¤œç´¢çµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.bib"
                        mime_type = "text/plain"
                        file_content = bibtex_content
                        button_label = "ğŸ“š BibTeXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                    
                    st.download_button(
                        label=button_label,
                        data=file_content,
                        file_name=filename,
                        mime=mime_type,
                        type="primary"
                    )
            
            # å„è«–æ–‡ã®è¡¨ç¤º
            for i, paper in enumerate(results, 1):
                display_paper_with_save(paper, search_query, i)
                
        else:
            st.warning("ğŸ” æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.markdown("""
            **ğŸ’¡ æ¤œç´¢ã®ã‚³ãƒ„:**
            - ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã¿ã¦ãã ã•ã„
            - è‹±èªã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚è©¦ã—ã¦ã¿ã¦ãã ã•ã„
            - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ•°ã‚’æ¸›ã‚‰ã—ã¦ã¿ã¦ãã ã•ã„
            - å¹´åº¦ç¯„å›²ã‚’åºƒã’ã¦ã¿ã¦ãã ã•ã„
            """)
    
    else:
        # åˆæœŸè¡¨ç¤ºï¼šã‚·ã‚¹ãƒ†ãƒ èª¬æ˜
        st.markdown("## ğŸ¯ EduStudyã«ã¤ã„ã¦")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ğŸ” æ¤œç´¢æ©Ÿèƒ½
            - **è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: Semantic Scholar + Google Scholar
            - **å¤šè¨€èªå¯¾å¿œ**: æ—¥æœ¬èªãƒ»è‹±èªã§ã®æ¤œç´¢ãŒå¯èƒ½
            - **æ•™è‚²ç‰¹åŒ–**: æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã«ç‰¹åŒ–ã—ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            - **ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º**: æ¤œç´¢èªã‚’çµæœå†…ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            - **é‡è¤‡é™¤å»**: è¤‡æ•°ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®é‡è¤‡è«–æ–‡ã‚’è‡ªå‹•é™¤å»
            """)
            
        with col2:
            st.markdown("""
            ### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            - **Semantic Scholar**: 200M+ å­¦è¡“è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            - **Google Scholar**: Googleã®å­¦è¡“æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³
            - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°**: æœ€æ–°ã®ç ”ç©¶æˆæœã‚’å³åº§ã«æ¤œç´¢
            - **å¼•ç”¨æƒ…å ±**: è«–æ–‡ã®å½±éŸ¿åº¦ã‚’å¼•ç”¨æ•°ã§ç¢ºèª
            - **ç›´æ¥ãƒªãƒ³ã‚¯**: è«–æ–‡ã®åŸæ–‡ã¸ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
            """)
        
        st.markdown("---")
        
        st.markdown("""
        ### ğŸš€ ä½¿ã„æ–¹
        1. **æ¤œç´¢èªå…¥åŠ›**: ä¸Šã®æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã«é–¢å¿ƒã®ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›
        2. **ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¤œç´¢çµæœæ•°ã‚„å¹´åº¦ç¯„å›²ã‚’èª¿æ•´
        3. **æ¤œç´¢å®Ÿè¡Œ**: ã€Œæ¤œç´¢é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        4. **çµæœç¢ºèª**: ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã•ã‚ŒãŸæ¤œç´¢çµæœã‚’ç¢ºèª
        5. **è«–æ–‡é–²è¦§**: æ°—ã«ãªã‚‹è«–æ–‡ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦åŸæ–‡ã‚’èª­ã‚€
        """)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray; font-size: 0.8em; padding: 2rem;'>
        <p>ğŸ“ EduStudy - æ•™è‚²è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ </p>
        <p>Powered by Semantic Scholar API & Google Scholar | ãƒ‡ãƒ¼ã‚¿ã¯å®šæœŸçš„ã«æ›´æ–°ã•ã‚Œã¾ã™</p>
        <p>ğŸ”¬ ç ”ç©¶è€…ã®çš†æ§˜ã®å­¦è¡“æ´»å‹•ã‚’æ”¯æ´ã—ã¾ã™</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
