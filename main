import streamlit as st
import requests
import re
from datetime import datetime
import time

def search_papers_api(query, limit=20):
    """Semantic Scholar APIã‚’ä½¿ç”¨ã—ã¦è«–æ–‡ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
    if not query:
        return []
    
    # Semantic Scholar API endpoint
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    
    # æ•™è‚²é–¢ä¿‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Š
    education_keywords = ["education", "learning", "teaching", "pedagogy", "educational"]
    enhanced_query = f"{query} {' OR '.join(education_keywords)}"
    
    params = {
        'query': enhanced_query,
        'limit': limit,
        'fields': 'paperId,title,authors,year,abstract,venue,citationCount,publicationDate,url'
    }
    
    try:
        response = requests.get(base_url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        papers = []
        for paper in data.get('data', []):
            # æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            title_abstract = (paper.get('title', '') + ' ' + paper.get('abstract', '')).lower()
            education_terms = ['education', 'learning', 'teaching', 'student', 'school', 'classroom', 'pedagogy', 'curriculum', 'instruction']
            
            if any(term in title_abstract for term in education_terms):
                processed_paper = {
                    'title': paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜'),
                    'authors': ', '.join([author.get('name', '') for author in paper.get('authors', [])]) or 'è‘—è€…ä¸æ˜',
                    'year': paper.get('year', 'å¹´åº¦ä¸æ˜'),
                    'abstract': paper.get('abstract', 'æŠ„éŒ²ãªã—'),
                    'venue': paper.get('venue', 'æ²è¼‰èªŒä¸æ˜'),
                    'citation_count': paper.get('citationCount', 0),
                    'url': paper.get('url', ''),
                    'publication_date': paper.get('publicationDate', '')
                }
                papers.append(processed_paper)
        
        return papers
    
    except requests.exceptions.RequestException as e:
        st.error(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []
    except Exception as e:
        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def highlight_text(text, search_terms):
    """æ¤œç´¢èªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹é–¢æ•°"""
    if not search_terms or not text:
        return text
    
    # è¤‡æ•°ã®æ¤œç´¢èªã«å¯¾å¿œ
    terms = [term.strip() for term in search_terms.split() if term.strip()]
    highlighted_text = text
    
    for term in terms:
        # å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„æ¤œç´¢
        pattern = re.compile(re.escape(term), re.IGNORECASE)
        highlighted_text = pattern.sub(
            f'<mark style="background-color: #ffeb3b; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{term}</mark>',
            highlighted_text
        )
    
    return highlighted_text

def display_paper(paper, search_query, index):
    """è«–æ–‡æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°"""
    with st.container():
        # è«–æ–‡ç•ªå·ã¨ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãï¼‰
        highlighted_title = highlight_text(paper['title'], search_query)
        st.markdown(f"### {index}. {highlighted_title}", unsafe_allow_html=True)
        
        # è‘—è€…æƒ…å ±ã¨å¹´åº¦
        col1, col2, col3 = st.columns([3, 1, 1])
        with col1:
            st.markdown(f"**è‘—è€…:** {paper['authors']}")
        with col2:
            st.markdown(f"**å¹´åº¦:** {paper['year']}")
        with col3:
            st.markdown(f"**å¼•ç”¨æ•°:** {paper['citation_count']}")
        
        # æ²è¼‰èªŒæƒ…å ±
        if paper['venue']:
            st.markdown(f"**æ²è¼‰èªŒ:** {paper['venue']}")
        
        # æŠ„éŒ²ï¼ˆãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãï¼‰
        if paper['abstract'] and paper['abstract'] != 'æŠ„éŒ²ãªã—':
            highlighted_abstract = highlight_text(paper['abstract'], search_query)
            # æŠ„éŒ²ã‚’é©åˆ‡ãªé•·ã•ã«åˆ¶é™
            if len(paper['abstract']) > 300:
                truncated_abstract = paper['abstract'][:300] + "..."
                highlighted_abstract = highlight_text(truncated_abstract, search_query)
            st.markdown(f"**æŠ„éŒ²:** {highlighted_abstract}", unsafe_allow_html=True)
        
        # è«–æ–‡ãƒªãƒ³ã‚¯
        if paper['url']:
            st.markdown(f"[ğŸ“„ è«–æ–‡ã‚’èª­ã‚€]({paper['url']})")
        
        st.markdown("---")

def main():
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title="æ•™è‚²é–¢ä¿‚å­¦ä¼šèªŒè«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ",
        page_icon="ğŸ“š",
        layout="wide"
    )
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
    }
    .search-box {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .paper-card {
        background: white;
        padding: 1.5rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“š æ•™è‚²é–¢ä¿‚å­¦ä¼šèªŒè«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ </h1>
        <p>ä¸–ç•Œä¸­ã®æ•™è‚²é–¢ä¿‚è«–æ–‡ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œç´¢ã§ãã¾ã™ã€‚Semantic Scholar APIã‚’ä½¿ç”¨ã—ã¦æœ€æ–°ã®ç ”ç©¶æˆæœã‚’æä¾›ã—ã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ” æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        # æ¤œç´¢çµæœæ•°ã®è¨­å®š
        result_limit = st.slider(
            "æ¤œç´¢çµæœæ•°",
            min_value=5,
            max_value=50,
            value=20,
            step=5
        )
        
        # å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        current_year = datetime.now().year
        year_range = st.slider(
            "ç™ºè¡Œå¹´åº¦ç¯„å›²",
            min_value=2000,
            max_value=current_year,
            value=(2020, current_year),
            step=1
        )
        
        st.markdown("---")
        st.markdown("**ğŸ’¡ æ¤œç´¢ã®ãƒ’ãƒ³ãƒˆ:**")
        st.markdown("- æ—¥æœ¬èªã¾ãŸã¯è‹±èªã§æ¤œç´¢å¯èƒ½")
        st.markdown("- è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›")
        st.markdown("- æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã«ç‰¹åŒ–ã—ã¦æ¤œç´¢")
        st.markdown("- å¼•ç”¨æ•°ã®å¤šã„è«–æ–‡ãŒä¸Šä½ã«è¡¨ç¤º")
        
        st.markdown("---")
        st.markdown("**ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:**")
        st.markdown("- Semantic Scholar API")
        st.markdown("- 200M+ å­¦è¡“è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
        st.markdown("- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°")
    
    # ãƒ¡ã‚¤ãƒ³æ¤œç´¢ã‚¨ãƒªã‚¢
    st.markdown('<div class="search-box">', unsafe_allow_html=True)
    
    col1, col2 = st.columns([4, 1])
    
    with col1:
        search_query = st.text_input(
            "ğŸ” æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: ãƒ‡ã‚¸ã‚¿ãƒ«æ•™æ, collaborative learning, AI education",
            help="æ—¥æœ¬èªã¾ãŸã¯è‹±èªã§æ¤œç´¢ã§ãã¾ã™ã€‚è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        )
    
    with col2:
        search_button = st.button("ğŸš€ æ¤œç´¢é–‹å§‹", type="primary", use_container_width=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # æ¤œç´¢å®Ÿè¡Œ
    if search_query and (search_button or search_query):
        with st.spinner("ğŸ” è«–æ–‡ã‚’æ¤œç´¢ä¸­..."):
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("Semantic Scholar APIã«æ¥ç¶šä¸­...")
            progress_bar.progress(25)
            
            # APIæ¤œç´¢å®Ÿè¡Œ
            results = search_papers_api(search_query, result_limit)
            progress_bar.progress(75)
            
            # å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if results:
                filtered_results = [
                    paper for paper in results 
                    if paper['year'] != 'å¹´åº¦ä¸æ˜' and 
                    isinstance(paper['year'], int) and 
                    year_range[0] <= paper['year'] <= year_range[1]
                ]
                results = filtered_results
            
            progress_bar.progress(100)
            status_text.text("æ¤œç´¢å®Œäº†!")
            time.sleep(0.5)
            progress_bar.empty()
            status_text.empty()
        
        # çµæœè¡¨ç¤º
        st.markdown(f"## ğŸ“Š æ¤œç´¢çµæœ: {len(results)}ä»¶")
        
        if results:
            # çµæœã®çµ±è¨ˆæƒ…å ±
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ğŸ“„ æ¤œç´¢çµæœæ•°", len(results))
            with col2:
                result_years = [paper['year'] for paper in results if isinstance(paper['year'], int)]
                st.metric("ğŸ“… æœ€æ–°å¹´åº¦", max(result_years) if result_years else "N/A")
            with col3:
                total_citations = sum([paper['citation_count'] for paper in results])
                st.metric("ğŸ“ˆ ç·å¼•ç”¨æ•°", total_citations)
            with col4:
                unique_venues = len(set([paper['venue'] for paper in results if paper['venue']]))
                st.metric("ğŸ“š é–¢é€£å­¦ä¼šèªŒæ•°", unique_venues)
            
            st.markdown("---")
            
            # å¼•ç”¨æ•°ã§ã‚½ãƒ¼ãƒˆ
            sorted_results = sorted(results, key=lambda x: x['citation_count'], reverse=True)
            
            # å„è«–æ–‡ã®è¡¨ç¤º
            for i, paper in enumerate(sorted_results, 1):
                display_paper(paper, search_query, i)
                
        else:
            st.warning("ğŸ” æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.markdown("""
            **ğŸ’¡ æ¤œç´¢ã®ã‚³ãƒ„:**
            - ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã¿ã¦ãã ã•ã„
            - è‹±èªã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚è©¦ã—ã¦ã¿ã¦ãã ã•ã„
            - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ•°ã‚’æ¸›ã‚‰ã—ã¦ã¿ã¦ãã ã•ã„
            - å¹´åº¦ç¯„å›²ã‚’åºƒã’ã¦ã¿ã¦ãã ã•ã„
            """)
    
    else:
        # åˆæœŸè¡¨ç¤ºï¼šã‚·ã‚¹ãƒ†ãƒ èª¬æ˜
        st.markdown("## ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ğŸ” æ¤œç´¢æ©Ÿèƒ½
            - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢**: Semantic Scholar APIã‚’ä½¿ç”¨
            - **å¤šè¨€èªå¯¾å¿œ**: æ—¥æœ¬èªãƒ»è‹±èªã§ã®æ¤œç´¢ãŒå¯èƒ½
            - **æ•™è‚²ç‰¹åŒ–**: æ•™è‚²é–¢ä¿‚ã®è«–æ–‡ã«ç‰¹åŒ–ã—ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            - **ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º**: æ¤œç´¢èªã‚’çµæœå†…ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            """)
            
        with col2:
            st.markdown("""
            ### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            - **200M+ è«–æ–‡**: ä¸–ç•Œæœ€å¤§ç´šã®å­¦è¡“è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°**: æœ€æ–°ã®ç ”ç©¶æˆæœã‚’å³åº§ã«æ¤œç´¢
            - **å¼•ç”¨æƒ…å ±**: è«–æ–‡ã®å½±éŸ¿åº¦ã‚’å¼•ç”¨æ•°ã§ç¢ºèª
            - **ç›´æ¥ãƒªãƒ³ã‚¯**: è«–æ–‡ã®åŸæ–‡ã¸ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
            """)
        
        st.markdown("---")
        
        st.markdown("""
        ### ğŸš€ ä½¿ã„æ–¹
        1. **æ¤œç´¢èªå…¥åŠ›**: ä¸Šã®æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã«é–¢å¿ƒã®ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›
        2. **ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¤œç´¢çµæœæ•°ã‚„å¹´åº¦ç¯„å›²ã‚’èª¿æ•´
        3. **æ¤œç´¢å®Ÿè¡Œ**: ã€Œæ¤œç´¢é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        4. **çµæœç¢ºèª**: ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã•ã‚ŒãŸæ¤œç´¢çµæœã‚’ç¢ºèª
        5. **è«–æ–‡é–²è¦§**: æ°—ã«ãªã‚‹è«–æ–‡ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦åŸæ–‡ã‚’èª­ã‚€
        """)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray; font-size: 0.8em; padding: 2rem;'>
        <p>ğŸ“š æ•™è‚²é–¢ä¿‚å­¦ä¼šèªŒè«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ </p>
        <p>Powered by Semantic Scholar API | ãƒ‡ãƒ¼ã‚¿ã¯å®šæœŸçš„ã«æ›´æ–°ã•ã‚Œã¾ã™</p>
        <p>ğŸ”¬ ç ”ç©¶è€…ã®çš†æ§˜ã®å­¦è¡“æ´»å‹•ã‚’æ”¯æ´ã—ã¾ã™</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
